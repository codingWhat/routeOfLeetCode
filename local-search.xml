<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>如何优雅迁移数据</title>
    <link href="/2024/10/23/how-to-migrate-data/"/>
    <url>/2024/10/23/how-to-migrate-data/</url>
    
    <content type="html"><![CDATA[<h2 id="数据迁移的背景"><a href="#数据迁移的背景" class="headerlink" title="数据迁移的背景"></a>数据迁移的背景</h2><p>基本上数据迁移无外乎如下原因</p><ul><li>业务增长</li><li>降本增效</li></ul><p>常见迁移的策略有如下两种方式</p><ol><li>停机迁移</li><li>不停机迁移</li></ol><p>像金融场景会采用第一种，一般会提前发布公告，在迁移期间服务不可用。<br>而大部分互联网的场景更倾向于采用不停机的优雅迁移策略。</p><h2 id="迁移时机"><a href="#迁移时机" class="headerlink" title="迁移时机"></a>迁移时机</h2><ul><li>已在测试环境模拟完毕</li><li>凌晨, 数据量少</li></ul><h2 id="迁移阶段"><a href="#迁移阶段" class="headerlink" title="迁移阶段"></a>迁移阶段</h2><ul><li>全量拷贝(mysqldump&#x2F;XtraBackup, redis-shake)</li><li>写旧、读旧</li><li>先写旧再写新，读旧(异步diff检测)</li><li>先写新再写旧，读新(异步diff检测)</li><li>写新、读新</li></ul><h2 id="全量拷贝"><a href="#全量拷贝" class="headerlink" title="全量拷贝"></a>全量拷贝</h2><h2 id="校准和修复逻辑"><a href="#校准和修复逻辑" class="headerlink" title="校准和修复逻辑"></a>校准和修复逻辑</h2><h2 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h2>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>GMP学习总结</title>
    <link href="/2024/08/09/gmp-understanding/"/>
    <url>/2024/08/09/gmp-understanding/</url>
    
    <content type="html"><![CDATA[<h2 id="调度器前世今生"><a href="#调度器前世今生" class="headerlink" title="调度器前世今生"></a>调度器前世今生</h2><p>调度器核心职责就是通过复用线程来高效执行G, 目前GMP模型已经非常高效了，然而调度器也是经过一步一步演进来的，早期调度器只有G、M以及全局‘runq’，性能表现并不出色，尤其随着goroutine数增长，当m从全局队列消费G时会导致锁竞争非常严重，除此之外系统调用、阻塞等操作时M会休眠，此时M上的G得不到执行，严重影响性能。为了解决这些问题，Go开发者重新设计调度器，推出了当前“GMP”模型。</p><h2 id="调度器核心概念"><a href="#调度器核心概念" class="headerlink" title="调度器核心概念"></a>调度器核心概念</h2><h3 id="Processor"><a href="#Processor" class="headerlink" title="Processor"></a>Processor</h3><p>职责:</p><ol><li>解决GM模型的全局锁问题</li><li><code>runq</code>和P绑定(GM模型中，M包含<code>runq</code>)，当M在执行阻塞调用休眠时，M和P解绑，P可以去找空闲M继续执行<code>runq</code>中的G</li></ol><p>P状态机:<br><img src="/images/gmp_p_status.png" alt="gmp_p_status"></p><h3 id="Goroutine"><a href="#Goroutine" class="headerlink" title="Goroutine"></a>Goroutine</h3><p>Goroutine简化版三种状态:</p><ul><li>Waiting, 阻塞&#x2F;系统调用中</li><li>Executing, 在M中正在执行</li><li>Runnable, 就绪状态，runq中</li></ul><p>G生命周期：</p><ul><li>_GIdle(空闲链表中) -&gt; _GDead(从链表中取出) -&gt; _GRunnable(参数复制、入栈等) -&gt; _GRunning</li><li>_GSyscall(系统调用) -&gt; _GRunning</li><li>_GWaiting(阻塞) -&gt; GRunnable</li></ul><p><img src="/images/g_status.png" alt="g_status"></p><p>G(用户)退出:<br>runtime·goexit1(mcall) -&gt; goexit0<br>先切换到G0 -&gt; 清空g的数据，解除和m的关系，g 的状态从 _Grunning 更新为 _Gdead，将g放入空闲队列</p><h3 id="G0-M0-P0-allgs-allm-allp"><a href="#G0-M0-P0-allgs-allm-allp" class="headerlink" title="G0,M0,P0,allgs,allm,allp"></a>G0,M0,P0,allgs,allm,allp</h3><ul><li>M0:是启动程序后的编号为0的主线程，这个M对应的实例会在全局变量runtime.m0中，M0负责执⾏初始化操作和启动第⼀个G， 在之后M0就和其他的M⼀样了。</li><li>G0: 是每次启动⼀个M都会第⼀个创建的gourtine，G0仅⽤于负责调度的G，G0不指向任何可执⾏的函数,每个M都会有⼀个⾃⼰的G0。在调度或系统调⽤时会使⽤G0的栈空间, 全局变量的G0是M0的G0。</li><li>allgs: 记录所有的G</li><li>allm: 记录所有的M</li><li>allp: 记录所有的P</li><li>sched: sched是调度器，这里记录着所有空闲的m,空闲的p,全局队列runq等等</li></ul><p><img src="/images/g0-p0-m0.png" alt="g0-p0-m0"></p><h3 id="Sysmon线程"><a href="#Sysmon线程" class="headerlink" title="Sysmon线程:"></a>Sysmon线程:</h3><p>和P不需要的关联的m，循环执行，主要指责包含:</p><ul><li>netpoll(fd事件)</li><li>retake (抢占)，抢占长时间运行的P</li><li>forcegc(定期执行gc)</li><li>scavenge heap (释放内存空间)</li></ul><h2 id="以Goroutine视角理解GMP"><a href="#以Goroutine视角理解GMP" class="headerlink" title="以Goroutine视角理解GMP"></a>以Goroutine视角理解GMP</h2><p>以Goroutine生命周期来看，更像是生产&#x2F;消费模型，goroutine被创建之后，放到对应P的”队列”中, 之后被调度器消费执行。</p><h3 id="启动流程"><a href="#启动流程" class="headerlink" title="启动流程"></a>启动流程</h3><p>初始化m0和g0，m0和主线程绑定，之后按core核数初始化所有P，将第一个P(即P0)和m0、g0绑定，剩余的P放入空闲队列中。之后会创建g1(runtime.main)，放入P0的本地队列中,之后m0的g0开始执行调度逻辑。</p><h3 id="生产goroutine"><a href="#生产goroutine" class="headerlink" title="生产goroutine"></a>生产goroutine</h3><p>在生产阶段，底层对应<code>newproc</code>逻辑，通过<code>runqput</code>存储到P里。P有两个地方存储G, <code>runnenxt</code> 和 <code>runq</code></p><ul><li>容量: <code>runnext</code>1个G，<code>runq</code>256个G，因此P总共可以存储257个G</li><li>区别： <code>runnext</code>存储的是下一个要执行的G，<code>runq</code>是一个队列</li></ul><p><code>runnext</code>和<code>runq</code>可以整体看成一个FIFO队列，<code>runnext</code>指向队尾元素；不过需要注意的是，当队列满的时候，<code>runnext</code>还是会被新的G抢占，被强占的G和<code>runq</code>的前半部分的G会被合并放到<code>全局runq</code>中。</p><p>细节交互:<br><img src="/images/g_to_p.png" alt="Goroutine和P交互细节"></p><h3 id="消费goroutine"><a href="#消费goroutine" class="headerlink" title="消费goroutine"></a>消费goroutine</h3><p>go1.20.11版本<br>调度逻辑: <code>runtime/proc.go</code>中的<code>schedule()</code>的<code>findRunnable()</code>方法</p><ol><li>保证公平，防止全局<code>runq</code>中的goroutine饿死， 按概率(<code>runtime.SchedTick%61==0</code>)从全局runq中获取G</li><li>从本地<code>runnext</code>和<code>runq</code>中获取</li><li>从全局<code>runq</code>中获取</li><li>从netpoll中获取G, 返回第一个，剩下的直接追加到全局<code>runq</code>的尾部</li><li>从其他P那偷取一半G</li></ol><blockquote><p>在P都很繁忙的场景下，<code>全局runq</code>中的G可能迟迟得不到调度，为了公平起见，调度器会统计<code>runtime.SchedTick</code>，每次调度都会++, 当<code>runtime.SchedTick%61==0</code>时,会从<code>全局runq</code>中获取G来执行(高优先级)。</p></blockquote><p>runtime&#x2F;proc.go</p><blockquote><p>按’概率’从全局<code>runq</code>中获取<br><img src="/images/gmp_global_runq_random.png" alt="gmp_global_runq_probability"><br>从本地<code>runq</code>中获取<br><img src="/images/gmp_local_runq.png" alt="get from local runq"><br>从全局<code>runq</code>中获取<br><img src="/images/get_from_global_runq.png" alt="get_from_global_runq"><br>从<code>netpoll</code>中获取<br><img src="/images/get_form_netpoll.png" alt="get_form_netpoll"><br>从其他P中获取一半G<br><img src="/images/steal_from_other_p.png" alt="steal_from_other_p"></p></blockquote><h2 id="Go调度器策略"><a href="#Go调度器策略" class="headerlink" title="Go调度器策略"></a>Go调度器策略</h2><h3 id="steal-work机制"><a href="#steal-work机制" class="headerlink" title="steal-work机制"></a>steal-work机制</h3><p>尝试4次, 每次随机选择一个P，尝试从”适合的”P中获取一半G</p><blockquote><p><img src="/images/stealwork.png" alt="stealwork"></p></blockquote><p>高效获取一半G:<br>从’pp’(受害者P)的<code>runq</code>中将其一半g取出写入batch(施害者P的<code>runq</code>)，更新<code>pp</code>(受害者)的<code>runq</code>头指针。</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs golang">batchHead := pp.runqtail<br>batch = &amp;pp.runq<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">runqgrab</span><span class="hljs-params">(pp *p // 受害者P, batch *[256]guintptr //施害者P的runq , batchHead <span class="hljs-type">uint32</span> //施害者P的队尾指针, stealRunNextG <span class="hljs-type">bool</span>)</span></span> <span class="hljs-type">uint32</span> &#123;<br><span class="hljs-keyword">for</span> &#123;<br>h := atomic.LoadAcq(&amp;pp.runqhead) <span class="hljs-comment">// load-acquire, synchronize with other consumers</span><br>t := atomic.LoadAcq(&amp;pp.runqtail) <span class="hljs-comment">// load-acquire, synchronize with the producer</span><br>n := t - h<br>n = n - n/<span class="hljs-number">2</span><br><br>        ....省略非核心...<br><span class="hljs-comment">//取出前半部分G</span><br><span class="hljs-keyword">for</span> i := <span class="hljs-type">uint32</span>(<span class="hljs-number">0</span>); i &lt; n; i++ &#123;<br>g := pp.runq[(h+i)%<span class="hljs-type">uint32</span>(<span class="hljs-built_in">len</span>(pp.runq))]<br>batch[(batchHead+i)%<span class="hljs-type">uint32</span>(<span class="hljs-built_in">len</span>(batch))] = g<br>&#125;<br><br><span class="hljs-keyword">if</span> atomic.CasRel(&amp;pp.runqhead, h, h+n) &#123; <span class="hljs-comment">// cas-release, commits consume</span><br><span class="hljs-keyword">return</span> n<br>&#125;<br>&#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="handoff机制"><a href="#handoff机制" class="headerlink" title="handoff机制"></a>handoff机制</h3><p>当前发现正在执行的G发生阻塞、系统调用、或者需要被抢占时，P和M会解绑，会给P绑定”可用的”M,继续执行。而M会休眠，当调用结束之后，找一个空闲的P，若找不到P，M会变成休眠状态，进入空闲队列，G会被加入到全局<code>runq</code></p><h3 id="抢占-retake"><a href="#抢占-retake" class="headerlink" title="抢占(retake)"></a>抢占(retake)</h3><p>遍历所有P，针对(_Prunning 和 _Psyscall)状态的P, 如果发现同时满足以下条件就抢占<br><img src="/images/preempt_cond.png" alt="preempt_cond"></p><ol><li>从上一次监控线程观察到 p对应的m处于系统调用&#x2F;运行时间已经超过10ms</li><li>p的运行队列里面有等待运行的goroutine</li><li>没有“无所事事”的 p; 这就意味着没有“找工 作”的 M，也没有空闲的 P，大家都在“忙”，可能有很多工作要做,因此要抢占当前的 P，让它来承担 一部分工作。</li></ol><p>抢占的实现:</p><ul><li>信号机制，注册<code>runtime.sighandler</code>,接收到信号<code>SIGURG</code>时，由操作系统中断转入内核空间，而后将所中断线程的执行上下文参数(例如寄存器 rip、rep 等)传递给处理函数。如果在 runtime.sighandler 中修改了这个上下文参数，操作系统则会根据修 改后的上下文信息恢复执行</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>GO</tag>
      
      <tag>GO-GMP</tag>
      
      <tag>Go调度原理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>实现高性能的本地缓存库</title>
    <link href="/2024/08/05/local-cache-go-impl/"/>
    <url>/2024/08/05/local-cache-go-impl/</url>
    
    <content type="html"><![CDATA[<blockquote><p>在日常高流量场景中(读多写少场景)，经常会使用本地缓存来应对热点流量，保障系统的稳定。可是你有没有好奇过它底层是怎么实现的？数据是如何管理的？如果你来设计一个缓存库，你会如何设计?</p></blockquote><span id="more"></span><h1 id="他山之石，可以攻玉"><a href="#他山之石，可以攻玉" class="headerlink" title="他山之石，可以攻玉"></a>他山之石，可以攻玉</h1><p>在开始之前，借助开源社区了解主流缓存库的种类、设计思想以及适用场景是一个明智的做法。通过这样的调研，可以了解到不同缓存库的特点和优势，并从中汲取经验，以设计出符合自己需求的缓存库。 为了方便学习和理解，我对主流库做了详细调研并整理出以下多维度对比图，帮助你更清晰地了解不同缓存库之间的差异和优势。</p><p><img src="/images/go_localcaches_compare.png" alt="主流缓存库对比"><br>上述中比较有意思的是Zero-Gc这个概念，我总结下关键信息:<br><strong>如何实现Zero-GC?</strong></p><ol><li>完全避免GC: 采用syscall.MMap申请堆外内存，gc就不会扫描</li><li>规避GC扫描策略: 数组(固定了指针数量) + 非指针map[uint64]uint32 + []byte(参考freecache) 或者 slice + 非指针的map + ringbuffer(参考bigcache)</li></ol><p><strong>如何选择？</strong><br>就笔者的经验来看，比如在http服务中，从缓存库读取[]byte内容，写入socket，这种场景Zero-GC库确实很高效比较适合(这也正是bigCache诞生的背景)。但是在业务逻辑中的海量操作都要经过序列化是不可接受的，会占用很多cpu资源，而非zero-gc就算gc会影响程序的性能，但是缓存项毕竟会淘汰不是无限的，再加上go现在的gc优化的也不错，所以权衡之下优先采用非Zero-GC库。</p><p>综上，没有一个缓存库适用于所有场景和问题, 每个缓存库的诞生都是为了解决特定场景下的特定问题, 不过这些问题种类不多主要分为以下几类:</p><ul><li>锁竞争。全局锁导致大量请求都在抢锁、休眠，严重影响性能</li><li>数据淘汰。内存资源有限，必须要按特定策略淘汰数据</li><li>GC问题。存储海量对象时，GC扫描的影响不容小觑</li></ul><hr><h1 id="实践出真知"><a href="#实践出真知" class="headerlink" title="实践出真知"></a>实践出真知</h1><p>接下来围绕上述三个问题来设计我们自己的高性能本地缓存库。</p><h2 id="设计目标"><a href="#设计目标" class="headerlink" title="设计目标"></a>设计目标</h2><ul><li>高性能, 减少锁竞争</li><li>使用简单，配置不能太复杂，要开箱即用</li><li>支持按key设置过期时间</li><li>支持自动淘汰(LRU)</li><li>不要求Zero-GC, 但也应该尽量减少GC</li></ul><h2 id="设计思路"><a href="#设计思路" class="headerlink" title="设计思路"></a>设计思路</h2><ul><li>锁竞争: 读写锁 + 数据分片</li><li>数据淘汰: LRU</li><li>高性能: 合并写操作; 批量更新;</li><li>GC优化: 我们的目标是减少GC，尽量减少对象分配</li></ul><h2 id="详细设计"><a href="#详细设计" class="headerlink" title="详细设计"></a>详细设计</h2><h3 id="API设计"><a href="#API设计" class="headerlink" title="API设计"></a>API设计</h3><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs golang"><br><span class="hljs-keyword">type</span> Cache <span class="hljs-keyword">interface</span> &#123;<br>Set(k <span class="hljs-type">string</span>, v any, ttl time.Duration) <span class="hljs-type">bool</span><br>Get(k <span class="hljs-type">string</span>) (v any, err <span class="hljs-type">error</span>)<br>Del(k <span class="hljs-type">string</span>)<br>Len() <span class="hljs-type">uint64</span><br>Close()<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="核心数据结构"><a href="#核心数据结构" class="headerlink" title="核心数据结构"></a>核心数据结构</h3><h4 id="cache"><a href="#cache" class="headerlink" title="cache"></a>cache</h4><p>cache中核心结构为store、policy、expireKeyTimers模块, store负责存储引擎的实现，policy负责淘汰机制，expireKeyTimers管理过期清理的定时任务，这三者共同组成了缓存库基础骨架。</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">type</span> cache <span class="hljs-keyword">struct</span> &#123;<br>size <span class="hljs-type">int</span><br><br>store            store   <span class="hljs-comment">// 读写锁 + 数据分片</span><br>policy           policy  <span class="hljs-comment">//链表淘汰策略，LRU等</span><br>ekt              *expireKeyTimers <span class="hljs-comment">//维护key的定期清理任务</span><br>accessUniqBuffer *uniqRingBuffer <span class="hljs-comment">// 合并Get操作，降低对链表的移动</span><br><br>accessEvtCh <span class="hljs-keyword">chan</span> []*list.Element <span class="hljs-comment">//批量Get操作，支持批量更新链表</span><br>updateEvtCh <span class="hljs-keyword">chan</span> *entExtendFunc  <span class="hljs-comment">//合并对链表的Update</span><br>addEvtCh    <span class="hljs-keyword">chan</span> *entExtendFunc  <span class="hljs-comment">//合并写操作(包含链表和map)</span><br>delEvtCh    <span class="hljs-keyword">chan</span> *keyExtendFunc  <span class="hljs-comment">//合并对链表的Del</span><br><br>isSync     <span class="hljs-type">bool</span> <span class="hljs-comment">//同步标识，会阻塞等待至写成功之后</span><br>setTimeout time.Duration <span class="hljs-comment">//阻塞等待超时时间</span><br>&#125;<br></code></pre></td></tr></table></figure><h4 id="store-存储引擎实现"><a href="#store-存储引擎实现" class="headerlink" title="store - 存储引擎实现"></a>store - 存储引擎实现</h4><p>store 提供增删改查的接口，可以根据自己的需求实现对应的接口，比如我们这里用就是shardedMap, 通过分片来降低锁的粒度, 减少锁竞争。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs azure">type store interface &#123;<br>    set(k string, v any)<br>    get(k string) (any, bool)<br>    del(k string)<br>    len() uint64<br>    clear()<br>&#125;<br>type shardedMap struct &#123;<br>    shards []*safeMap<br>&#125;<br>    <br>type safeMap struct &#123;<br>mu   sync.RWMutex<br>data map[string]any<br>&#125;<br><br></code></pre></td></tr></table></figure><h4 id="policy-淘汰机制"><a href="#policy-淘汰机制" class="headerlink" title="policy - 淘汰机制"></a>policy - 淘汰机制</h4><p>淘汰机制主要是在对数据增删改查时，通过一定的策略来移动链表元素，以保证活跃的缓存项留在内存中，同时淘汰不活跃的缓存项。常见淘汰策略有LRU、LFU等。LRU较简单，可以通过标准库中的list实现policy接口实现。</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-comment">// 缓存项，包含 key,value,过期时间</span><br><span class="hljs-keyword">type</span> entry <span class="hljs-keyword">struct</span> &#123;<br>    key      <span class="hljs-type">string</span><br>    val      any<br>    expireAt time.Time<br>    mu sync.RWMutex<br>&#125;<br><span class="hljs-keyword">type</span> policy <span class="hljs-keyword">interface</span> &#123;<br>isFull() <span class="hljs-type">bool</span><br>add(*entry) (*list.Element, *list.Element) <span class="hljs-comment">// 返回新增, victim:淘汰的entry</span><br>remove(*list.Element)<br>update(*entry, *list.Element)<br>renew(*list.Element)<br>batchRenew([]*list.Element)<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="expireKeyTimers-过期时间"><a href="#expireKeyTimers-过期时间" class="headerlink" title="expireKeyTimers - 过期时间"></a>expireKeyTimers - 过期时间</h4><p>这个模块主要维护过期key的定时清理任务。底层主要依赖第三方<a href="https://github.com/RussellLuo/timingwheel">时间轮库</a>来管理定时任务</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">type</span> expireKeyTimers <span class="hljs-keyword">struct</span> &#123;<br>mu     sync.RWMutex<br>timers <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]*timingwheel.Timer<br><br>tick      time.Duration<br>wheelSize <span class="hljs-type">int64</span><br>tw        *timingwheel.TimingWheel<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="hash函数选型"><a href="#hash函数选型" class="headerlink" title="hash函数选型"></a>hash函数选型</h3><p><a href="https://github.com/smallnest/hash-bench">常见hash函数压测对比</a><br><img src="/images/hash_func.png" alt="常见hash函数"></p><hr><p>fnv64 vs xxhash<br>测试机器: mac-m1, go benchmark结果</p><table><thead><tr><th>hash函数</th><th>fnv64a</th><th>github.com&#x2F;cespare&#x2F;xxhash&#x2F;v2</th></tr></thead><tbody><tr><td>8字节</td><td>5.130 ns&#x2F;op</td><td>8.817 ns&#x2F;op</td></tr><tr><td>16字节</td><td>7.928 ns&#x2F;op</td><td>7.464 ns&#x2F;op</td></tr><tr><td>32字节</td><td>17.17 ns&#x2F;op</td><td>14.22 ns&#x2F;op</td></tr></tbody></table><h3 id="高性能优化"><a href="#高性能优化" class="headerlink" title="高性能优化"></a>高性能优化</h3><h4 id="写操作"><a href="#写操作" class="headerlink" title="写操作"></a>写操作</h4><p><strong>隔离:</strong>  按channel隔离增、删、改<br><strong>同步转异步:</strong>  链表并发写操作，改为异步单协程更新<br><strong>支持非阻塞</strong></p><h4 id="读操作"><a href="#读操作" class="headerlink" title="读操作"></a>读操作</h4><p><strong>批量操作:</strong> 采用ringbuffer，批量更新链表</p><h4 id="内存优化"><a href="#内存优化" class="headerlink" title="内存优化"></a>内存优化</h4><p>采用sync.Pool池化ringbuffer对象，避免频繁创建对象</p><h2 id="压测对比"><a href="#压测对比" class="headerlink" title="压测对比"></a>压测对比</h2><p><a href="https://github.com/codingWhat/armory/tree/main/cache/localcache">代码地址</a><br>同步模式:</p><table><thead><tr><th>压测case</th><th>操作次数</th><th>单次耗时 (ns&#x2F;op)</th><th>内存分配 (B&#x2F;op)</th><th>分配次数</th></tr></thead><tbody><tr><td>BenchmarkSyncMapSetParallelForStruct-10</td><td>1,576,032</td><td>719.3</td><td>76</td><td>5</td></tr><tr><td><strong>BenchmarkRistrettoSetParallelForStruct-10</strong></td><td>716,690</td><td>1,642</td><td>369</td><td>11</td></tr><tr><td>BenchmarkFreeCacheSetParallelForStruct-10</td><td>2,122,884</td><td>562.7</td><td>61</td><td>4</td></tr><tr><td>BenchmarkBigCacheSetParallelForStruct-10</td><td>2,206,600</td><td>546.9</td><td>200</td><td>4</td></tr><tr><td><strong>BenchmarkLCSetParallelForStruct-10</strong></td><td>914,626</td><td>1,279</td><td>282</td><td>9</td></tr><tr><td>BenchmarkSyncMapGetParallelForStruct-10</td><td>3,933,157</td><td>305.5</td><td>24</td><td>1</td></tr><tr><td>BenchmarkFreeCacheGetParallelForStruct-10</td><td>2,159,518</td><td>577.2</td><td>263</td><td>7</td></tr><tr><td>BenchmarkBigCacheGetParallelForStruct-10</td><td>2,218,573</td><td>539.1</td><td>279</td><td>8</td></tr><tr><td><strong>BenchmarkRistrettoGetParallelForStruct-10</strong></td><td>3,195,711</td><td>379.0</td><td>31</td><td>1</td></tr><tr><td><strong>BenchmarkLCGetParallelForStruct-10</strong></td><td>2,233,429</td><td>530.5</td><td>31</td><td>2</td></tr></tbody></table><p>总结:</p><ul><li>读取性能: LC 和 SyncMap 在读取操作中表现最佳，具有较低的耗时和内存分配。</li><li>写入性能: BigCache 和 FreeCache 在写入操作中表现较好，LC、Ristretto因为channel缘故，写入性能较差。</li><li>内存效率: SyncMap&#x2F;Ristretto 在Get操作中的内存分配最低，FreeCache在Set操作中内存分配最低, 整体上syncMap占用最低。</li></ul><p>非同步模式:<br>读、写、耗时、内存分配逐渐接近主流库的, 但是写存在失败的概率，需要按场景权衡。</p><table><thead><tr><th>压测case</th><th>操作次数</th><th>单次耗时 (ns&#x2F;op)</th><th>内存分配 (B&#x2F;op)</th><th>分配次数 (allocs&#x2F;op)</th></tr></thead><tbody><tr><td>BenchmarkSyncMapSetParallelForStruct-10</td><td>1256974</td><td>958.8</td><td>78</td><td>5</td></tr><tr><td><strong>BenchmarkRistrettoSetParallelForStruct-10</strong></td><td>2372764</td><td>505.6</td><td>143</td><td>4</td></tr><tr><td>BenchmarkFreeCacheSetParallelForStruct-10</td><td>2117694</td><td>554.2</td><td>61</td><td>4</td></tr><tr><td>BenchmarkBigCacheSetParallelForStruct-10</td><td>2130927</td><td>547.5</td><td>206</td><td>4</td></tr><tr><td><strong>BenchmarkLCSetParallelForStruct-10</strong></td><td>2115037</td><td>567.1</td><td>158</td><td>6</td></tr><tr><td>BenchmarkSyncMapGetParallelForStruct-10</td><td>3854450</td><td>305.2</td><td>23</td><td>1</td></tr><tr><td>BenchmarkFreeCacheGetParallelForStruct-10</td><td>2152428</td><td>560.6</td><td>263</td><td>7</td></tr><tr><td>BenchmarkBigCacheGetParallelForStruct-10</td><td>2202607</td><td>539.5</td><td>279</td><td>8</td></tr><tr><td><strong>BenchmarkRistrettoGetParallelForStruct-10</strong></td><td>3445798</td><td>349.7</td><td>31</td><td>1</td></tr><tr><td><strong>BenchmarkLCGetParallelForStruct-10</strong></td><td>2453848</td><td>505.4</td><td>30</td><td>2</td></tr></tbody></table><h2 id="未来展望"><a href="#未来展望" class="headerlink" title="未来展望"></a>未来展望</h2><p>继续优化写场景下，临时对象的管理，减少耗时操作和频繁的内存申请。</p>]]></content>
    
    
    
    <tags>
      
      <tag>GO</tag>
      
      <tag>本地缓存</tag>
      
      <tag>LRU</tag>
      
      <tag>高性能</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>服务可用性-理论篇</title>
    <link href="/2024/07/28/service-avaliable/"/>
    <url>/2024/07/28/service-avaliable/</url>
    
    <content type="html"><![CDATA[<h1 id="服务可用性-理论指导"><a href="#服务可用性-理论指导" class="headerlink" title="服务可用性-理论指导"></a>服务可用性-理论指导</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>服务可用性是指<code>服务正常运行的时间/服务实际运行的时间</code>, 不过专业来说应该是<code>可用性=MTTF / (MTTR+MTTF) * 100%</code>, MTTF(Mean time to failure) 平均无故障时间，MTTR(Mean time to repair)平均故障修复时间,MTTF衡量可用性。<br>MTTF越长说明系统可用性越好，越稳定。MTTR则代表系统恢复速度，值越小说明系统鲁棒性越好。<br><img src="/images/available_metric.png" alt="MTTF、MTTR、MTBF"></p><h2 id="重要性"><a href="#重要性" class="headerlink" title="重要性"></a>重要性</h2><p>假设用户使用你的产品不是在报错、就是白屏，系统频繁故障，你想想会发生什么？我们来详细分析下这个问题。<br>从用户角度来看:</p><ul><li>信任感越来越低</li><li>体验感越来越差</li><li>卸载app</li></ul><p>从公司角度来看:</p><ul><li>收入损失</li><li>口碑一落千丈</li><li>影响股价</li><li>舆论压力</li></ul><p>从开发来角度看:</p><ul><li>加班</li><li>325，半年白干</li><li>可能工作都没了</li></ul><p>综上来看可用性必须要足够重视，作为开发一定要竭尽所能保证系统可用性(稳定)。</p><h2 id="故障的种类"><a href="#故障的种类" class="headerlink" title="故障的种类"></a>故障的种类</h2><p><img src="/images/sa_fail_type.png" alt="故障种类"></p><p>如图故障主要分为以上5类，其中只有<code>变更类</code>是主动触发的，其他都是外部因素导致的，不过还是需要重视和解决。</p><h1 id="如何衡量可用性"><a href="#如何衡量可用性" class="headerlink" title="如何衡量可用性?"></a>如何衡量可用性?</h1><p><img src="/images/sa_formula.png" alt="可用性衡量"></p><p>这里的关键是<code>MTTR</code>(平均故障修复时间)，而<code>MTTR</code>又可以分为:<br><code>MTTI</code>(mean time to identify), 平均故障识别时间，这个阶段会通过各个渠道(告警、舆情、用户反馈)收到故障信息<br><code>MTTK</code>(mean time to know), 平均故障认知时间，定位业务、定位对应开发、开发定位问题根因所花时间<br><code>MTTS</code>(mean time to solve), 平均故障解决时间，这部分主要包含上线修复、验证的时间</p><p><img src="/images/sa_mttr_detail.png" alt="MTTR细节"></p><h2 id="如何提升可用性"><a href="#如何提升可用性" class="headerlink" title="如何提升可用性?"></a>如何提升可用性?</h2><p>基于上述的<code>可用性公式</code>，只能缩短<code>MTTR</code>，也就是说:</p><ul><li><code>减少故障数量</code></li><li><code>加快问题发现定位[MTTI+MTTK]</code></li><li><code>加快问题解决[MTTS]</code>。</li></ul><p><img src="/images/sa_pre_handle_fail_and_fail_identify_solve.png" alt="提升可用性"></p><p>知道了解决方向之后，我们结合<code>研发流程</code>分别从<code>事前</code>、<code>事中</code>以及<code>事后</code>三个阶段来阐述各环节的内容。</p><h3 id="减少故障数量【事前】"><a href="#减少故障数量【事前】" class="headerlink" title="减少故障数量【事前】"></a>减少故障数量【事前】</h3><p><img src="/images/sa_pre_online.png" alt="上线前 + 上线中"></p><h3 id="代码质量"><a href="#代码质量" class="headerlink" title="代码质量"></a>代码质量</h3><ul><li>建立代码规范，统一标准  </li><li>严格的code review</li></ul><h3 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h3><ul><li>异步解耦和削峰设计（消息队列）</li><li>可扩展性设计; 分层、无状态</li></ul><h3 id="风险控制"><a href="#风险控制" class="headerlink" title="风险控制"></a>风险控制</h3><ul><li>限流</li><li>降级</li><li>熔断</li><li>重试</li><li>隔离</li><li>兼容性</li></ul><p>常规治理手段: 可查看《<a href="https://codingwhat.github.io/2024/07/17/serive-high-available-governance/">服务可用性治理</a>》</p><h4 id="容量评估"><a href="#容量评估" class="headerlink" title="容量评估"></a>容量评估</h4><ul><li>对于提前预知的流量(春节、赛事活动等)，提前做好扩容。</li><li>预留容量buffer</li><li>弹性伸缩</li></ul><h4 id="测试验证"><a href="#测试验证" class="headerlink" title="测试验证"></a>测试验证</h4><ul><li>单测、集成测试</li><li>回归测试、功能测试、兼容性测试</li></ul><h4 id="变更规范"><a href="#变更规范" class="headerlink" title="变更规范"></a>变更规范</h4><ul><li>发布顺序</li><li>可灰度，代码发布, 金丝雀发布，将故障影响降到最低；配置变更支持灰度</li><li>可监控，根据告警信息，跟踪链路，定位错误日志信息</li><li>可回滚，代码&#x2F;配置</li></ul><p>一定要满足<code>可监控</code> 、<code>可灰度</code> 、 <code>可回滚</code></p><h3 id="运行中-【事中】"><a href="#运行中-【事中】" class="headerlink" title="运行中 【事中】"></a>运行中 【事中】</h3><p><img src="/images/sa_fail_identify.png" alt="故障监测"></p><h3 id="故障发现-MTTI"><a href="#故障发现-MTTI" class="headerlink" title="故障发现(MTTI)"></a>故障发现(MTTI)</h3><p>1.内部，配置告警，监测系统异常(基础资源、服务)<br>2.外部，舆情&#x2F;客服&#x2F;反馈平台获取。</p><h4 id="故障认知-MTTK"><a href="#故障认知-MTTK" class="headerlink" title="故障认知(MTTK)"></a>故障认知(MTTK)</h4><ul><li>tracing + Log + metric 快速定位</li></ul><h4 id="故障解决-MTTS"><a href="#故障解决-MTTS" class="headerlink" title="故障解决(MTTS)"></a>故障解决(MTTS)</h4><p><img src="/images/sa_fail_solve.png" alt="故障解决"></p><ul><li>回滚，发现异常快速回滚线上变更，降低影响面</li><li>下线，下线故障节点</li><li>扩容，如果发现流量异常，及时扩容</li><li>容灾切换开关, 比如idc有异常，做流量切换</li><li>限流，针对服务、接口、appid做不同的限流配置。</li><li>熔断, 下游异常时，调整熔断配置，直接拒绝请求，避免资源浪费、堆积</li><li>降级，在发生异常时，可以通过打开开关，走降级逻辑，比如用户标签信息服务异常，可以先展示默认信息。</li><li>重启</li><li>代码bugfix</li></ul><h3 id="故障复盘【事后】"><a href="#故障复盘【事后】" class="headerlink" title="故障复盘【事后】"></a>故障复盘【事后】</h3><ul><li>时间线 </li><li>根因分析</li><li>定责定级</li><li>优化逻辑</li><li>沉淀解决方案&#x2F;工具，避免重蹈覆辙。</li></ul><p><img src="/images/sa_process.png" alt="稳定性各环节"></p><h1 id="服务质量指标-工程实践"><a href="#服务质量指标-工程实践" class="headerlink" title="服务质量指标-工程实践"></a>服务质量指标-工程实践</h1><p>主要包含SLA、SLI、SLO、这三个指标分别对应 <code>协议</code>、<code>指标</code>、<code>目标</code>。<br>SLA一般是对外的，比如付费业务通常都会制定SLA协议，如果服务不满足协议要求，会有对应的赔偿方案，可参考<a href="https://cloud.tencent.com/document/product/301/103169#63ee1985-f56f-4629-afbf-cafde690ca64">腾讯云SLA</a><br>SLI和SLO关系好比是指标和值的关系，比如<code>push触达率:99.9%</code> 即 SLI: push触达率, SLO: 99.9%</p><h2 id="如何制定质量指标？"><a href="#如何制定质量指标？" class="headerlink" title="如何制定质量指标？"></a>如何制定质量指标？</h2><p>在实际工程中，首先需要决策服务可用性采用”几个9”? 比如”99.9%”, “99.99%”以及”99.999%”，可用性依次越来越高，至于选几个9不是拍脑袋定的。</p><h3 id="第一步-了解自身服务的特点"><a href="#第一步-了解自身服务的特点" class="headerlink" title="第一步: 了解自身服务的特点"></a>第一步: 了解自身服务的特点</h3><ul><li>确认系统提供什么类型的服务?</li><li>确认不同故障的影响如何?</li><li>确认成本和可用性之间的关系？</li></ul><h4 id="确认系统提供什么类型的服务"><a href="#确认系统提供什么类型的服务" class="headerlink" title="确认系统提供什么类型的服务?"></a>确认系统提供什么类型的服务?</h4><ol><li>付费还是免费?</li><li>是否对公司收入非常重要?</li><li>竞争对手提供什么服务?</li><li>to B 还是 to C?</li></ol><h4 id="确认不同故障的影响如何"><a href="#确认不同故障的影响如何" class="headerlink" title="确认不同故障的影响如何?"></a>确认不同故障的影响如何?</h4><ol><li>确认计划外故障(断断续续故障(快速修复)，还是直接宕机(关闭服务))</li><li>计划内故障</li></ol><h4 id="确认成本和可用性之间的关系？"><a href="#确认成本和可用性之间的关系？" class="headerlink" title="确认成本和可用性之间的关系？"></a>确认成本和可用性之间的关系？</h4><ol><li>提升一个9需要付出多少成本，两者之间的权衡</li></ol><h3 id="第二步-确定服务质量指标"><a href="#第二步-确定服务质量指标" class="headerlink" title="第二步: 确定服务质量指标"></a>第二步: 确定服务质量指标</h3><ol><li>可用性级别: 是否高可靠</li><li>故障类型: 是否能容忍故障</li><li>成本: 比如有的客户端要求延时，有的需要吞吐，需要根据不同需求场景，优化成本不一致</li></ol><h3 id="第三步-制定质量方案"><a href="#第三步-制定质量方案" class="headerlink" title="第三步:制定质量方案"></a>第三步:制定质量方案</h3><ol><li>设置SLO、错误预算(裁决：功能迭代 vs  系统稳定)</li><li>监控指标, 立体监控</li></ol><p><strong>如何选择SLI</strong><br>这里需要说明下，<code>可用性时间</code>在某些场景下会产生歧义(<a href="https://sre.google/sre-book/embracing-risk/">SRE-计划外停机</a>)，并不会作为SLI出现，相反成功率、请求延时、吞吐、连接数这些指标反而更常见。比如一个长连接网关系统，可能会更加关注连接数、延时、吞吐等<br>而评论系统可能更加关注吞吐、成功率等。所以SLI指标跟业务的关注点是分不开的。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><blockquote><p><a href="https://sre.google/sre-book/embracing-risk/">《Google SRE》</a></p></blockquote>]]></content>
    
    
    
    <tags>
      
      <tag>GO</tag>
      
      <tag>可用性治理</tag>
      
      <tag>微服务</tag>
      
      <tag>服务可用性</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>服务可用性治理-实践篇</title>
    <link href="/2024/07/17/serive-high-available-governance/"/>
    <url>/2024/07/17/serive-high-available-governance/</url>
    
    <content type="html"><![CDATA[<blockquote><p> 本文将围绕节点、架构以及外部工具三个方面介绍服务治理。通过理论结合实践的方式帮助读者逐步掌握相关概念和技能，并能将其应用于实际工作中。本文内容是基于个人学习和实践的总结，如果有任何错误或不准确之处，欢迎指正。</p></blockquote><span id="more"></span><h1 id="单节点"><a href="#单节点" class="headerlink" title="单节点"></a>单节点</h1><p>想象一下如果你的服务只部署在一个节点上，并且你的系统恰好面临以下问题，作为服务owner你会怎么应对呢?</p><ul><li>如果有异常流量怎么办？(超过平时流量的数倍)</li><li>如果依赖的服务挂了怎么办？</li><li>如果服务过载了怎么办？</li></ul><h2 id="限流"><a href="#限流" class="headerlink" title="限流"></a>限流</h2><p><img src="/images/limiter.png" alt="限流模型"><br>我们知道单节点的处理能力是有限的，所以对于异常流量第一步我们要做的就是限流保护系统。限流主要有分为客户端限流、服务端限流以及分布式限流。这几种限流场景我在另一篇<a href="https://codingwhat.github.io/2024/07/09/limiter-in-action/">《限流实战》</a>做了详细分析，所以这里不再重复了。</p><h2 id="熔断"><a href="#熔断" class="headerlink" title="熔断"></a>熔断</h2><p>熔断为什么能提高可用性?<br>1.当依赖服务&#x2F;组件发生故障时，断路器会打开，此时无需请求下游，业务要么降级要么fast-fail，有效的避免了资源浪费以及资源堆积引发的雪崩效应。<br>2.断路器会通过探针探测服务是否恢复，如果发现服务恢复了，会继续放行请求，提升可用性。</p><p><strong>断路器分类</strong></p><ul><li>传统断路器，<a href="https://github.com/afex/hystrix-go">hystrix-go</a>&#x2F;<a href="https://github.com/alibaba/sentinel-golang/tree/master/core/circuitbreaker">sentinel-go</a></li><li>自适应熔断, google sre-breaker</li></ul><h3 id="传统断路器"><a href="#传统断路器" class="headerlink" title="传统断路器"></a>传统断路器</h3><p><img src="/images/circuit_breaker.png" alt="传统断路器"><br>网上介绍断路器的文章很多, 本文偏实战这里就不详细介绍了, 我这里挑重点介绍<br><strong>状态机原理:</strong><br>它是一个状态机模型，通过状态切换处理故障减少对主调的影响，主要包含三种状态:打开(Open)、半打开(Half-Open)、关闭(Closed)<br>以下是断路器的基本逻辑：<br>1.初始状态下，断路器处于关闭状态（Closed）。<br>2.当下游服务出现故障时，断路器会统计相应的指标，如错误率、错误数或慢调用。如果这些指标超过了用户定义的阈值（比如错误数的静默数等），则断路器进入打开状态（Open）。<br>3.在打开状态下，断路器会等待一个用户定义的时间窗口，然后进入半打开状态（Half Open）。<br>4.在半打开状态下，断路器会放行一定数量的探针请求，并根据探针的结果进行判断（用户定义探针数和探针成功的比例）。<br>5.如果所有的探针请求都成功，说明下游服务已经恢复正常，断路器将重新进入关闭状态（Closed）。<br>6.如果探针请求失败或未达到成功比例的要求，断路器将继续保持打开状态（Open），并继续进行探测。</p><p>断路器的优点在于它提供了丰富的配置选项，可以根据具体需求来设置错误率、慢调用比例、错误数等指标。然而，由于配置项较多，准确地配置这些值可能会有一定的挑战。</p><details><summary> hystrix-go实现</summary><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;fmt&quot;</span><br><span class="hljs-string">&quot;net/http&quot;</span><br><span class="hljs-string">&quot;time&quot;</span><br><br><span class="hljs-string">&quot;github.com/afex/hystrix-go/hystrix&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-comment">// 设置一个命令名为&quot;callOutRPC&quot;的断路器</span><br>hystrix.ConfigureCommand(<span class="hljs-string">&quot;callOutRPC&quot;</span>, hystrix.CommandConfig&#123;<br>Timeout:                <span class="hljs-type">int</span>(<span class="hljs-number">3</span> * time.Second), <span class="hljs-comment">// rpc调用超时时间</span><br>MaxConcurrentRequests:  <span class="hljs-number">10</span>,                   <span class="hljs-comment">// 并发请求10个，用chanel控制</span><br>SleepWindow:            <span class="hljs-number">5000</span>,                 <span class="hljs-comment">//单位ms, open-&gt;half open 睡眠窗口</span><br>RequestVolumeThreshold: <span class="hljs-number">10</span>,                   <span class="hljs-comment">// 静默数，这里就是错误数必须要&gt;=10个</span><br>ErrorPercentThreshold:  <span class="hljs-number">30</span>,                   <span class="hljs-comment">//错误率阈值</span><br>&#125;)<br><br>_ = hystrix.Do(<span class="hljs-string">&quot;callOutRPC&quot;</span>, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> <span class="hljs-type">error</span> &#123;<br><span class="hljs-comment">// 尝试调用远端服务</span><br>_, err := http.Get(<span class="hljs-string">&quot;https://www.1baidu.com&quot;</span>)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> err<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(err <span class="hljs-type">error</span>)</span></span> <span class="hljs-type">error</span> &#123;<br><span class="hljs-comment">// 快速失败时的回调函数</span><br>fmt.Println(<span class="hljs-string">&quot;call rpc failed. now calling fallback logic&quot;</span>)<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;)<br>&#125;<br></code></pre></td></tr></table></figure></details><details><summary>sentinel-go实现</summary><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><code class="hljs golang"><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span> <span class="hljs-params">()</span></span> &#123;<br>    <span class="hljs-keyword">if</span> err := InitCircuitBreaker(); err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-built_in">panic</span>(err)<br>    &#125;<br>    <br>e, b := sentinel.Entry(<span class="hljs-string">&quot;calleeSrv&quot;</span>)<br><span class="hljs-keyword">if</span> b != <span class="hljs-literal">nil</span> &#123;<br>    <span class="hljs-comment">// 触发熔断</span><br>    <span class="hljs-comment">// metric上报</span><br><span class="hljs-keyword">return</span> ret, b<br>&#125;<br>err := callOutRpc()<br>e.Exit(base.WithError(err))<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">callOutRpc</span><span class="hljs-params">()</span></span> <span class="hljs-type">error</span> &#123;<br>    time.Sleep(<span class="hljs-number">1</span> * time.Second)<br>    <span class="hljs-keyword">return</span> errors.New(<span class="hljs-string">&quot;happend error&quot;</span>)<br>&#125;<br><span class="hljs-comment">// InitCircuitBreaker 初始化断路器</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">InitCircuitBreaker</span><span class="hljs-params">()</span></span> <span class="hljs-type">error</span> &#123;<br>err := sentinel.InitDefault()<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> err<br>&#125;<br>defaultRules := []*circuitbreaker.Rule&#123;<br>&#123;<br>Resource:                     <span class="hljs-string">&quot;calleeSrv&quot;</span>,                  <span class="hljs-comment">// 名字</span><br>Strategy:                     circuitbreaker.SlowRequestRatio, <span class="hljs-comment">// 慢查询</span><br>RetryTimeoutMs:               <span class="hljs-number">5000</span>,                            <span class="hljs-comment">// 5s后尝试恢复，进入half状态</span><br>MinRequestAmount:             <span class="hljs-number">100</span>,                             <span class="hljs-comment">// 静默数 Open的前置条件, 100，主要针对热点</span><br>StatIntervalMs:               <span class="hljs-number">2000</span>,                            <span class="hljs-comment">// 2s钟慢查询比例不超过0.4</span><br>StatSlidingWindowBucketCount: <span class="hljs-number">100</span>,                             <span class="hljs-comment">// 每个格子 20ms</span><br>MaxAllowedRtMs:               <span class="hljs-number">130</span>,                             <span class="hljs-comment">// (120 + 10(buffer)))毫秒以外算慢查询</span><br>Threshold:                    <span class="hljs-number">0.5</span>,                             <span class="hljs-comment">// 5s钟慢查询比例不超过0.4</span><br>ProbeNum:                     <span class="hljs-number">10</span>,<br>&#125;,<br>&#125;<br>circuitbreaker.RegisterStateChangeListeners(&amp;stateChangeTestListener&#123;&#125;)<br>_, err = circuitbreaker.LoadRules(defaultRules)<br><span class="hljs-keyword">return</span> err<br>&#125;<br><br><span class="hljs-keyword">type</span> stateChangeTestListener <span class="hljs-keyword">struct</span> &#123;<br>&#125;<br><br><span class="hljs-comment">// OnTransformToClosed 转换至关闭状态回调函数</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *stateChangeTestListener)</span></span> OnTransformToClosed(prev circuitbreaker.State, rule circuitbreaker.Rule) &#123;<br>CircuitBreakerClosed.Inc()<br>log.Infof(<span class="hljs-string">&quot;rule.strategy: %+v, From %s to Closed, time: %v\n&quot;</span>, rule.Strategy, prev.String(),<br>util.FormatTimeMillis(util.CurrentTimeMillis()))<br><br>&#125;<br><br><span class="hljs-comment">// OnTransformToOpen 转换至开启状态回调函数</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *stateChangeTestListener)</span></span> OnTransformToOpen(prev circuitbreaker.State, rule circuitbreaker.Rule,<br>snapshot <span class="hljs-keyword">interface</span>&#123;&#125;) &#123;<br>CircuitBreakerOpen.Inc()<br>log.Infof(<span class="hljs-string">&quot;rule.strategy: %+v, From %s to Open, snapshot: %.2f, time: %v\n&quot;</span>, rule.Strategy, prev.String(),<br>snapshot, util.FormatTimeMillis(util.CurrentTimeMillis()))<br>&#125;<br><br><span class="hljs-comment">// OnTransformToHalfOpen 转换至半开状态回调函数</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *stateChangeTestListener)</span></span> OnTransformToHalfOpen(prev circuitbreaker.State, rule circuitbreaker.Rule) &#123;<br>CircuitBreakerHalfOpen.Inc()<br>log.Infof(<span class="hljs-string">&quot;rule.strategy: %+v, From %s to Half-Open, time: %v\n&quot;</span>, rule.Strategy, prev.String(),<br>util.FormatTimeMillis(util.CurrentTimeMillis()))<br>&#125;<br></code></pre></td></tr></table></figure></details><h3 id="自适应断路器"><a href="#自适应断路器" class="headerlink" title="自适应断路器"></a>自适应断路器</h3><p><strong>google sre-breaker</strong> 出自书籍《Google SRE》中Handling Overload节</p><p><img src="/images/sre_breaker.png" alt="谷歌自适应断路器-核心算法"><br>传统断路器在Open状态时有固定的等待窗口，窗口内会拒绝所有请求，以此来保障服务的稳定性，不过在短暂抖动的场景下，这种策略反而会降低服务的可用性(比如等待窗口10s, 可是服务3s就恢复了，还得等待7s才会进入half-open), GoogleSRE提供了一个解决方案-自适应客户端限流，通过滑窗口统计成功请求数、请求总数采用上图算法决策是否放行探针，较传统方式能更快的感知到下游服务的恢复情况<br>算法: f(x) &#x3D; max(0, (requests - K * accepts)&#x2F;(requests+1))</p><p><strong>算法剖析：</strong><br>初始状态: requests &#x3D;&#x3D; accepts,假设K&#x3D;0.5,<br>无故障时: f(x) &gt;  0, 当故障开始时, requests变大, accepts保持不变, f(x)一直 &gt; 0<br>假设K&#x3D;1<br>无故障时: f(x) &#x3D;&#x3D; 0, 当故障开始时, requests变大, accepts保持不变，当requests &gt; 1 * accepts时 f(x) &gt; 0<br>假设K&#x3D;2<br>无故障时: f(x) &#x3D;&#x3D; 0, 当故障开始时, requests变大, accepts保持不变, 当requests &gt; 2 * accepts时, f(x) &gt; 0</p><p>综上，K是调节熔断刚性的因子，当K&gt;&#x3D;1,偏柔性，比如K&#x3D;1, 此时相当于能容忍accepts个请求通过，当K&lt;1, 则偏刚性，直接拒绝了。</p><p><strong>总结:</strong></p><ul><li>少了很多自定义配置，开发只需要调节K这个变量; K越小越激进</li><li>实时性更好点，不会有固定的等待窗口</li></ul><p><strong>代码实现</strong><br>可以参考<a href="https://github.com/go-kratos/kratos/blob/v1.0.x/pkg/net/netutil/breaker/sre_breaker.go">B站实现</a></p><p><img src="/images/bilibili_sre.png" alt="B站使用效果"></p><h2 id="超时控制"><a href="#超时控制" class="headerlink" title="超时控制"></a>超时控制</h2><p><strong>超时控制的必要性</strong></p><ul><li>防止资源浪费，不能及时释放资源，满足fast-fail</li><li>避免雪崩效应，故障扩散</li></ul><h3 id="超时策略"><a href="#超时策略" class="headerlink" title="超时策略"></a>超时策略</h3><ul><li>固定超时</li><li>EMA动态超时</li></ul><h3 id="固定超时"><a href="#固定超时" class="headerlink" title="固定超时"></a>固定超时</h3><ul><li>链路超时</li><li>服务内超时</li></ul><p><strong>链路超时控制:</strong><br>假设链路调用关系: A(300ms)-&gt;B(200ms)-&gt;C(100ms), 链路总超时为1s<br>链路超时传递为: A(used:300ms, left:700) -&gt; B (used:200ms, left:500ms) -&gt; C (used:100ms, left:400ms)</p><p><img src="/images/timeout_propagation.png" alt="链路超时传递"></p><p><strong>如何传递?</strong></p><ul><li>grpc中是通过http2的HEADERS Frame透传， <code>grpc-timeout</code> 字段</li></ul><p><strong>服务内超时控制:</strong><br>假设服务超时为600ms，有三个串行的RPC调用[A(500ms), B(300ms), C(100ms)]，在调用B时会等待300ms后会触发超时。很明显这里超时是可以优化的, timeout&#x3D;min(timeout, time.Util(deadline)), 比如deadline剩10ms，rpc超时为100ms，那就没必要等100ms。(http请求，go已经帮我们做好了)<br><strong>如何传递?</strong></p><details>  <summary> 利用context.WithTimeout 实现</summary><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">package main<br><br><span class="hljs-keyword">import</span> (<br>&quot;context&quot;<br>&quot;fmt&quot;<br>&quot;log&quot;<br>&quot;time&quot;<br>)<br><br>func main() &#123;<br>// 创建一个上下文，并设置总超时时间为<span class="hljs-number">600</span>毫秒<br>ctx, cancel := context.WithTimeout(context.Background(), <span class="hljs-number">600</span>*<span class="hljs-type">time</span>.Millisecond)<br>defer cancel()<br><br>// 启动A、B、C三个调用，并传递父上下文<br>callA(ctx)<br>callB(ctx)<br>callC(ctx)<br><br>// 等待<span class="hljs-number">1</span>秒钟，等待所有调用完成<br><span class="hljs-type">time</span>.Sleep(<span class="hljs-type">time</span>.Second)<br>&#125;<br><br>func callA(parentCtx context.Context) &#123;<br>// 根据父上下文的截止时间计算A调用的超时时间<br>deadline, ok := parentCtx.Deadline()<br><span class="hljs-keyword">if</span> !ok &#123;<br><span class="hljs-keyword">log</span>.Println(&quot;Parent context does not have a deadline&quot;)<br><span class="hljs-keyword">return</span><br>&#125;<br>timeout := <span class="hljs-number">500</span> * <span class="hljs-type">time</span>.Millisecond<br><span class="hljs-keyword">if</span> timeout &gt; <span class="hljs-type">time</span>.<span class="hljs-keyword">Until</span>(deadline) &amp;&amp; <span class="hljs-type">time</span>.Now().<span class="hljs-keyword">Before</span>(deadline) &#123;<br>timeout = <span class="hljs-type">time</span>.<span class="hljs-keyword">Until</span>(deadline)<br>&#125;<br>fmt.Println(&quot;callA---&gt;&quot;, <span class="hljs-type">time</span>.<span class="hljs-keyword">Until</span>(deadline))<br><br>// 创建一个子上下文，并设置A调用的超时时间<br>ctx, cancel := context.WithTimeout(parentCtx, timeout)<br>defer cancel()<br><br><span class="hljs-keyword">select</span> &#123;<br><span class="hljs-keyword">case</span> &lt;-<span class="hljs-type">time</span>.<span class="hljs-keyword">After</span>(<span class="hljs-number">500</span> * <span class="hljs-type">time</span>.Millisecond):<br><span class="hljs-keyword">log</span>.Println(&quot;Call A completed&quot;)<br><span class="hljs-keyword">case</span> &lt;-ctx.Done():<br><span class="hljs-keyword">log</span>.Println(&quot;Call A timed out&quot;)<br>&#125;<br>&#125;<br><br>func callB(parentCtx context.Context) &#123;<br>// 根据父上下文的截止时间计算B调用的超时时间<br>deadline, ok := parentCtx.Deadline()<br><span class="hljs-keyword">if</span> !ok &#123;<br><span class="hljs-keyword">log</span>.Println(&quot;Parent context does not have a deadline&quot;)<br><span class="hljs-keyword">return</span><br>&#125;<br>fmt.Println(&quot;callB---&gt;&quot;, <span class="hljs-type">time</span>.<span class="hljs-keyword">Until</span>(deadline))<br>timeout := <span class="hljs-number">300</span> * <span class="hljs-type">time</span>.Millisecond<br><span class="hljs-keyword">if</span> timeout &gt; <span class="hljs-type">time</span>.<span class="hljs-keyword">Until</span>(deadline) &amp;&amp; <span class="hljs-type">time</span>.Now().<span class="hljs-keyword">Before</span>(deadline) &#123;<br>timeout = <span class="hljs-type">time</span>.<span class="hljs-keyword">Until</span>(deadline)<br>&#125;<br><br>// 创建一个子上下文，并设置B调用的超时时间<br>ctx, cancel := context.WithTimeout(parentCtx, timeout)<br>defer cancel()<br><br><span class="hljs-keyword">select</span> &#123;<br><span class="hljs-keyword">case</span> &lt;-<span class="hljs-type">time</span>.<span class="hljs-keyword">After</span>(<span class="hljs-number">300</span> * <span class="hljs-type">time</span>.Millisecond):<br><span class="hljs-keyword">log</span>.Println(&quot;Call B completed&quot;)<br><span class="hljs-keyword">case</span> &lt;-ctx.Done():<br><span class="hljs-keyword">log</span>.Println(&quot;Call B timed out&quot;)<br>&#125;<br>&#125;<br><br>func callC(parentCtx context.Context) &#123;<br>// 根据父上下文的截止时间计算C调用的超时时间<br>deadline, ok := parentCtx.Deadline()<br><span class="hljs-keyword">if</span> !ok &#123;<br><span class="hljs-keyword">log</span>.Println(&quot;Parent context does not have a deadline&quot;)<br><span class="hljs-keyword">return</span><br>&#125;<br><br>timeout := <span class="hljs-number">100</span> * <span class="hljs-type">time</span>.Millisecond<br><span class="hljs-keyword">if</span> timeout &gt; <span class="hljs-type">time</span>.<span class="hljs-keyword">Until</span>(deadline) &amp;&amp; <span class="hljs-type">time</span>.Now().<span class="hljs-keyword">Before</span>(deadline) &#123;<br>timeout = <span class="hljs-type">time</span>.<span class="hljs-keyword">Until</span>(deadline)<br>&#125;<br>// 创建一个子上下文，并设置C调用的超时时间<br>ctx, cancel := context.WithTimeout(parentCtx, timeout)<br>defer cancel()<br><br><span class="hljs-keyword">select</span> &#123;<br><span class="hljs-keyword">case</span> &lt;-<span class="hljs-type">time</span>.<span class="hljs-keyword">After</span>(<span class="hljs-number">100</span> * <span class="hljs-type">time</span>.Millisecond):<br><span class="hljs-keyword">log</span>.Println(&quot;Call C completed&quot;)<br><span class="hljs-keyword">case</span> &lt;-ctx.Done():<br><span class="hljs-keyword">log</span>.Println(&quot;Call C timed out&quot;)<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure></details><h3 id="动态超时"><a href="#动态超时" class="headerlink" title="动态超时"></a>动态超时</h3><p>传统的超时控制一般会根据下游服务p90、p95超时时间静态设置，然而，当网络出现短暂的抖动时，会导致一些请求的响应时间变得异常长，从而产生长尾请求。为了解决这个问题，可以采用动态超时的方法，通过统计历史数据（包括成功和失败的请求数）来动态调整超时时间。<br><a href="https://github.com/fefeding/ema-timeout">ema算法原理</a>:<br>当平均响应时间(EMA)大于超时时间(Thwm)说明网络环境比较差，动态超时时长(Tdto)就会趋向于超时时长(Thwm), 缩短超时时长。当平均响应时间(EMA)小于超时时间(Thwm),说明平均情况表现很好，动态超时时长就可以适当超出超时时间(Thwm),但要小于最大弹性时间(Tmax).<br><img src="/images/ema.png" alt="EMA动态超时控制算法"></p><p>代码实现:</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;fmt&quot;</span><br><span class="hljs-string">&quot;math&quot;</span><br><span class="hljs-string">&quot;math/rand&quot;</span><br>)<br><br><span class="hljs-keyword">type</span> Ema <span class="hljs-keyword">struct</span> &#123;<br>options <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-type">float64</span><br>ema     <span class="hljs-type">float64</span><br>r       <span class="hljs-type">float64</span><br>&#125;<br><br><span class="hljs-comment">/*</span><br><span class="hljs-comment">*      Tavg: 最低响应时间， 一般用平均响应时间替代 (ms)</span><br><span class="hljs-comment">*      Thwm：超时时间限制， 确保最坏的时候，所有请求能处理。正常时正确处理的成功率满足需求。 (ms)</span><br><span class="hljs-comment">*      Tmax: 最大弹性时间 (ms)</span><br><span class="hljs-comment">*      N: 平滑指数， 平滑因子决定了最新数据的权重，越大，最新数据的权重越高，EMA对数据的变化更加敏感。而旧数据的权重则通过(1-α)进行衰减，随着时间的推移，旧数据的影响逐渐减小。</span><br><span class="hljs-comment">*/</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewEma</span><span class="hljs-params">()</span></span> *Ema &#123;<br>options = <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-type">float64</span>&#123;<br><span class="hljs-string">&quot;Tavg&quot;</span>: <span class="hljs-number">60</span>,<br><span class="hljs-string">&quot;Thwm&quot;</span>: <span class="hljs-number">250</span>, <span class="hljs-comment">//超时时间</span><br><span class="hljs-string">&quot;Tmax&quot;</span>: <span class="hljs-number">500</span>, <span class="hljs-comment">//最大超时时间</span><br><span class="hljs-string">&quot;N&quot;</span>:    <span class="hljs-number">50</span>,<br>&#125;<br><span class="hljs-keyword">return</span> &amp;Ema&#123;<br>options: options,<br>ema:     <span class="hljs-number">0</span>, <span class="hljs-comment">//平均响应时间</span><br>r:       <span class="hljs-number">2</span> / (options[<span class="hljs-string">&quot;N&quot;</span>] + <span class="hljs-number">1</span>),<br>&#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(e *Ema)</span></span> Update(x <span class="hljs-type">float64</span>) <span class="hljs-type">float64</span> &#123;<br><span class="hljs-comment">// 满足指数滑动平均值</span><br>ema := x*e.r + e.ema*(<span class="hljs-number">1</span>-e.r)<br>e.ema = ema<br><span class="hljs-keyword">return</span> ema<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(e *Ema)</span></span> Get() <span class="hljs-type">float64</span> &#123;<br><span class="hljs-keyword">var</span> tdto <span class="hljs-type">float64</span><br><span class="hljs-keyword">if</span> e.ema &lt;= e.options[<span class="hljs-string">&quot;Tavg&quot;</span>] &#123;<br>tdto = e.options[<span class="hljs-string">&quot;Tmax&quot;</span>]<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> e.ema &gt;= e.options[<span class="hljs-string">&quot;Thwm&quot;</span>] &#123;<br>tdto = e.options[<span class="hljs-string">&quot;Thwm&quot;</span>]<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>p := (e.options[<span class="hljs-string">&quot;Thwm&quot;</span>] - e.ema) / (e.options[<span class="hljs-string">&quot;Thwm&quot;</span>] - e.options[<span class="hljs-string">&quot;Tavg&quot;</span>])<br>tdto = e.options[<span class="hljs-string">&quot;Thwm&quot;</span>] + p*(e.options[<span class="hljs-string">&quot;Tmax&quot;</span>]-e.options[<span class="hljs-string">&quot;Thwm&quot;</span>])<br>&#125;<br><span class="hljs-keyword">return</span> math.Abs(tdto)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>ema := NewEma()<br><br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">100</span>; i++ &#123;<br>a := rand.Float64() * <span class="hljs-number">200</span><br>e := ema.Update(a)<br>t := ema.Get()<br>fmt.Println(a, e, t)<br>&#125;<br><br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">100</span>; i++ &#123;<br>a := rand.Float64()*<span class="hljs-number">200</span> + <span class="hljs-number">500</span><br>e := ema.Update(a)<br>t := ema.Get()<br>fmt.Println(a, e, t)<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>使用方法:</p><ul><li>非关键链路<br>缩短超时时间(Thwm), 相对小, 降低非核心链路耗时以及资源消耗</li><li>关键链路<br>延长超时时间(Thwm), 能有效缓解短暂网络抖动导致的长尾请求</li></ul><h3 id="超时时间选择"><a href="#超时时间选择" class="headerlink" title="超时时间选择"></a>超时时间选择</h3><ul><li>存量服务可以选用p99、p95作为超时时间</li></ul><h2 id="降级"><a href="#降级" class="headerlink" title="降级"></a>降级</h2><p>降级一般有以下几种策略</p><ul><li>一致性降级，强一致变弱一致</li><li>功能降级，下线非核心功能</li><li>用户体验降级, 不展示用户标签、个性化信息等</li><li>同步转异步，同步逻辑转化为异步，会有些延迟</li></ul><p>降级一般都和限流、熔断放在一起讨论，适合具体问题具体分析，本质是提供有损服务。这里就不多介绍理论内容，我给大家举几个实际场景，感受下即可。</p><ol><li>双11为了节省资源，tb或pdd会暂时关闭退货功能</li><li>视频平台推荐页会缓存首页的数据，防止进来就是白页</li><li>评论列表里有用户的各种信息，比如勋章等身份信息，如果获取失败这里返回空</li><li>还有一些计数场景，app评论&#x2F;点赞，如果是同步操作，很容易因为网络问题直接报错体验不好。一般都是异步静默提交，页面做假显。</li></ol><h2 id="重试"><a href="#重试" class="headerlink" title="重试"></a>重试</h2><h3 id="重试识别"><a href="#重试识别" class="headerlink" title="重试识别"></a>重试识别</h3><p>可以通过http staus code识别错误类型，比如4xx类型明显就是请求有问题就别重试了；还有些情况可能需要根据响应中code码去识别，比如参数错误、鉴权失败等也不应该重试。</p><h3 id="重试策略"><a href="#重试策略" class="headerlink" title="重试策略"></a>重试策略</h3><p>确认重试之后, 首先要限制重试的比例，其次重点关注重试次数和重试间隔，重试间隔我们可以采用以下策略:</p><ul><li>固定间隔, interval: base; 实现简单但是这种策略很容易出现重试波峰</li><li>随机间隔, interval: base + rand; 打散重试时间，减少重试波峰；虽然每个请求重试时间不一样，但是下游如果短时间内不能恢复，就会收到大量请求可能会造成服务雪崩。</li><li>随机 + 指数退避, interval: (exp)^retryNum + rand; 减少了重试波峰以及对下游的重试压力；超时配置需要注意，不要影响核心链路的耗时</li></ul><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs golang"><br><span class="hljs-keyword">type</span> RetryStrategy <span class="hljs-type">int</span><br><br><span class="hljs-keyword">const</span> (<br>Fixed  RetryStrategy = <span class="hljs-number">0</span> <span class="hljs-comment">// 固定值, n, n, n...</span><br>Linear RetryStrategy = <span class="hljs-number">1</span> <span class="hljs-comment">// 线性, n, 2n, 3n...</span><br>Exp    RetryStrategy = <span class="hljs-number">2</span> <span class="hljs-comment">// 指数, n, 2n, 4n, 8n...</span><br>Rand   RetryStrategy = <span class="hljs-number">3</span> <span class="hljs-comment">// 随机, [n, 2n]</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">sleep</span><span class="hljs-params">(i, milliSec <span class="hljs-type">int</span>, s RetryStrategy)</span></span> time.Duration &#123;<br>n := milliSec<br><span class="hljs-keyword">switch</span> s &#123;<br><span class="hljs-keyword">case</span> Linear:<br>n = i*milliSec + milliSec<br><span class="hljs-keyword">case</span> Exp:<br>n = <span class="hljs-type">int</span>(math.Pow(<span class="hljs-number">2</span>, <span class="hljs-type">float64</span>(i))) * milliSec<br><span class="hljs-keyword">case</span> Rand:<br>n = rand.Intn(milliSec+<span class="hljs-number">1</span>) + milliSec<br><span class="hljs-keyword">default</span>:<br>&#125;<br><span class="hljs-keyword">return</span> time.Millisecond * time.Duration(n)<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="对冲策略"><a href="#对冲策略" class="headerlink" title="对冲策略"></a>对冲策略</h3><p>这个概念源自GRPC, 是指在不等待响应的情况下主调主动发送多个请求，本质是更加激进的重试。 适用于一些流量不大的场景，可以缓解短暂网络抖动导致的长尾请求，不过一定确认好重试对下游负载的影响。<br>如下图，假设主调和被调超时时间为60ms，第一个请求发出之后会触发一个10ms定时器, 假设主调在10ms内没有收到响应，定时器就会触发立即发送重试请求，如果重试请求响应先返回了，就会立即返回，第一个请求的响应会被主调丢弃。<br><img src="/images/hedging.png" alt="对冲模型"></p><details> <summary>对冲模拟实现</summary><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br><br>request, err := http.NewRequest(<span class="hljs-string">&quot;Get&quot;</span>, <span class="hljs-string">&quot;http://www.baidu.com&quot;</span>, <span class="hljs-literal">nil</span>)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-built_in">panic</span>(err)<br>&#125;<br>hedged, err := retryHedged(request, <span class="hljs-number">3</span>, <span class="hljs-number">10</span>*time.Millisecond, <span class="hljs-number">10</span>*time.Second, Backoff)<br>fmt.Println(hedged, err)<br>&#125;<br><br><span class="hljs-keyword">type</span> RetryStrategy <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(<span class="hljs-type">int</span>)</span></span> time.Duration<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Backoff</span><span class="hljs-params">(retryNum <span class="hljs-type">int</span>)</span></span> time.Duration &#123;<br><span class="hljs-keyword">return</span> time.Duration(retryNum*<span class="hljs-number">2</span>+<span class="hljs-number">2</span>) * time.Millisecond<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">retryHedged</span><span class="hljs-params">(req *http.Request, maxRetries <span class="hljs-type">int</span>, hedgeDelay time.Duration, reqTimeout time.Duration, rs RetryStrategy)</span></span> (*http.Response, <span class="hljs-type">error</span>) &#123;<br><span class="hljs-keyword">var</span> (<br>originalBody []<span class="hljs-type">byte</span><br>err          <span class="hljs-type">error</span><br>)<br><span class="hljs-keyword">if</span> req != <span class="hljs-literal">nil</span> &amp;&amp; req.Body != <span class="hljs-literal">nil</span> &#123;<br>originalBody, err = copyBody(req.Body)<br>&#125;<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>&#125;<br><br>AttemptLimit := maxRetries<br><span class="hljs-keyword">if</span> AttemptLimit &lt;= <span class="hljs-number">0</span> &#123;<br>AttemptLimit = <span class="hljs-number">1</span><br>&#125;<br><br>client := http.Client&#123;<br>Timeout: reqTimeout,<br>&#125;<br><br><span class="hljs-comment">// 每次请求copy新的request</span><br>copyRequest := <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> (request *http.Request) &#123;<br>request = req.Clone(req.Context())<br><span class="hljs-keyword">if</span> request.Body != <span class="hljs-literal">nil</span> &#123;<br>resetBody(request, originalBody)<br>&#125;<br><span class="hljs-keyword">return</span><br>&#125;<br><br>multiplexCh := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span> &#123;<br>resp  *http.Response<br>err   <span class="hljs-type">error</span><br>retry <span class="hljs-type">int</span><br>&#125;)<br><br>totalSentRequests := &amp;sync.WaitGroup&#123;&#125;<br>allRequestsBackCh := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;)<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>totalSentRequests.Wait()<br><span class="hljs-built_in">close</span>(allRequestsBackCh)<br>&#125;()<br><span class="hljs-keyword">var</span> resp *http.Response<br><br><span class="hljs-keyword">var</span> (<br>canHedge   <span class="hljs-type">uint32</span><br>readyHedge = <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;)<br>)<br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; AttemptLimit; i++ &#123;<br>totalSentRequests.Add(<span class="hljs-number">1</span>)<br><br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(i <span class="hljs-type">int</span>)</span></span> &#123;<br><span class="hljs-keyword">if</span> atomic.CompareAndSwapUint32(&amp;canHedge, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>) &#123;<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>&lt;-time.After(hedgeDelay)<br>readyHedge &lt;- <span class="hljs-keyword">struct</span>&#123;&#125;&#123;&#125;<br>&#125;()<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>&lt;-readyHedge<br>time.Sleep(rs(i))<br>&#125;<br><span class="hljs-comment">// 标记已经执行完</span><br><span class="hljs-keyword">defer</span> totalSentRequests.Done()<br>req = copyRequest()<br>resp, err = client.Do(req)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>fmt.Printf(<span class="hljs-string">&quot;error sending the first time: %v\n&quot;</span>, err)<br>&#125;<br><span class="hljs-comment">// 重试 500 以上的错误码</span><br><span class="hljs-keyword">if</span> err == <span class="hljs-literal">nil</span> &amp;&amp; resp.StatusCode &lt; <span class="hljs-number">500</span> &#123;<br>multiplexCh &lt;- <span class="hljs-keyword">struct</span> &#123;<br>resp  *http.Response<br>err   <span class="hljs-type">error</span><br>retry <span class="hljs-type">int</span><br>&#125;&#123;resp: resp, err: err, retry: i&#125;<br><span class="hljs-keyword">return</span><br>&#125;<br><span class="hljs-comment">// 如果正在重试，那么释放fd</span><br><span class="hljs-keyword">if</span> resp != <span class="hljs-literal">nil</span> &#123;<br>resp.Body.Close()<br>&#125;<br><span class="hljs-comment">// 重置body</span><br><span class="hljs-keyword">if</span> req.Body != <span class="hljs-literal">nil</span> &#123;<br>resetBody(req, originalBody)<br>&#125;<br>&#125;(i)<br>&#125;<br><br><span class="hljs-keyword">select</span> &#123;<br><span class="hljs-keyword">case</span> res := &lt;-multiplexCh:<br><span class="hljs-keyword">return</span> res.resp, res.err<br><span class="hljs-keyword">case</span> &lt;-allRequestsBackCh:<br><span class="hljs-comment">// 到这里，说明全部的 goroutine 都执行完毕，但是都请求失败了</span><br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, errors.New(<span class="hljs-string">&quot;all req finish，but all fail&quot;</span>)<br>&#125;<br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">copyBody</span><span class="hljs-params">(src io.ReadCloser)</span></span> ([]<span class="hljs-type">byte</span>, <span class="hljs-type">error</span>) &#123;<br>b, err := io.ReadAll(src)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>&#125;<br>src.Close()<br><span class="hljs-keyword">return</span> b, <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">resetBody</span><span class="hljs-params">(request *http.Request, originalBody []<span class="hljs-type">byte</span>)</span></span> &#123;<br>request.Body = io.NopCloser(bytes.NewBuffer(originalBody))<br>request.GetBody = <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> (io.ReadCloser, <span class="hljs-type">error</span>) &#123;<br><span class="hljs-keyword">return</span> io.NopCloser(bytes.NewBuffer(originalBody)), <span class="hljs-literal">nil</span><br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure></details><h3 id="重试总结"><a href="#重试总结" class="headerlink" title="重试总结"></a>重试总结</h3><ol><li>明确好哪些情况下才能重试</li><li><font color="red"> 重试只在当前层. </font> 当重试失败时，应该约定全局错误码，“no need retry” 避免及联重试</li><li>一定注意<font color="red">随机化重试间隔时间</font>，避免重试波峰</li><li>下游一定是幂等的，不能产生副作用</li></ol><h1 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h1><h2 id="冗余架构"><a href="#冗余架构" class="headerlink" title="冗余架构"></a>冗余架构</h2><ul><li>同城灾备</li><li>同城双活</li><li>两地三中心</li><li>异地双活<br>这部分可以直接看<a href="http://kaito-kidd.com/2021/10/15/what-is-the-multi-site-high-availability-design/">这篇文章</a>写的非常好</li></ul><p>这里以双中心架构为例(不过同城双活、两地三中心更常见)<br><img src="/images/two_idc.png" alt="双中心架构"><br>整体架构通过GSLB将流量划分为北京和广州，覆盖接入层、服务层、存储层，形成异地”双活”(一般都是读双活，写双活成本高，一致性容易出问题) </p><ul><li>服务层做读写分离，以上图为例, 北京(读写), 广州(读), 广州的写请求路由到北京;</li><li>存储也是各自一套，以mysql为例, master节点在北京(因为北京负责写)，广州为备份节点，自动从北京master异步同步，保持最终一致。</li></ul><p>用户请求链路:<br>用户(北京、电信用户) 请求经过DNS(GSLB)域名解析返回北京电信sgtw的IP，之后请求会转发到stgw，由sgtw通过内网隧道转发到API网关。</p><ul><li>sgtw是我司收敛不同运营商的网关(七层流量负载均衡; 解决跨运营商访问延时大的问题)</li></ul><h3 id="单元化架构"><a href="#单元化架构" class="headerlink" title="单元化架构"></a>单元化架构</h3><p>单元化架构是将系统划分成不同的业务单元，将同一单元的业务部署在一个机房，在单元内实现业务自包含。如下图服务的上下游组成独立、完整的单元并且部署在一起，链路调用绝对不会产生跨机房延时问题。<br><img src="/images/set_arch.png" alt="单元化架构">,</p><p><strong>单元架构分类</strong><br>这里以阿里云的介绍为例：<br>RZone（Region Zone）：部署按用户维度拆分的关键业务系统。核心业务和数据单元化拆分，拆分后分片均衡，单元内尽量自包含（调用封闭），拥有自己的数据，能完成所有业务。一个可用区可以有多个 RZone。<br>GZone（Global Zone）：部署未按用户维度拆分的系统，被 RZone 依赖，提供不可拆分的数据和服务，如配置型的业务。数据库可以和 RZone 共享，多租户隔离，全局只有一组，可以配置流量权重。<br>CZone（City Zone）：部署未按用户维度拆分的系统，被 RZone 高频访问 ，解决跨域通信延时问题。为了解决异地延迟问题而特别设计，适合读多写少且不可拆分的业务。 一般每个城市一套应用和数据，是 GZone 的快照。</p><p><img src="/images/logic_set_type.png" alt="单元化架构-单元类型"></p><h2 id="自动故障转移"><a href="#自动故障转移" class="headerlink" title="自动故障转移"></a>自动故障转移</h2><ul><li>API网关故障转移</li><li>客户端故障转移</li><li>自适应重试</li><li>负载均衡</li></ul><h3 id="API网关故障转移"><a href="#API网关故障转移" class="headerlink" title="API网关故障转移"></a>API网关故障转移</h3><p>如果网关发现本地AZ不可用时，会自动故障转移，路由到其他地域的AZ解决故障。为了防止重试流量压垮异地，需要控制重试次数<br><img src="/images/api_gateway_failover.png" alt="网关故障转移"></p><h3 id="客户端故障转移"><a href="#客户端故障转移" class="headerlink" title="客户端故障转移"></a>客户端故障转移</h3><p>客户端就近访问本地网关时，如果发现本地网关不可用，可以重试异地网关解决故障。</p><h3 id="自适应重试"><a href="#自适应重试" class="headerlink" title="自适应重试"></a>自适应重试</h3><p><strong>设置合理的重试窗口</strong><br>实现思路: 依旧请求结果[成功率]来动态调整重试窗口。若成功率满足阈值，当前重试次数超过窗口，则适当增加窗口，否则保持窗口大小；若不满足成功率,窗口阈值&#x3D;max(1, num&#x2F;2)</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;fmt&quot;</span><br><span class="hljs-string">&quot;math/rand&quot;</span><br>)<br><br><span class="hljs-keyword">type</span> RetryLimiter <span class="hljs-keyword">struct</span> &#123;<br>CurRetryWindowSize <span class="hljs-type">int</span> <span class="hljs-comment">//重试窗口</span><br>CurUsedQuota       <span class="hljs-type">int</span><br>&#125;<br><br><span class="hljs-comment">// GetRetryQuota 获取重试配额</span><br><span class="hljs-comment">// succRate 滑窗统计最近成功率，比如最近5s</span><br><span class="hljs-comment">// retryProbeNum: 重试次数</span><br><span class="hljs-comment">// reqIdx: 本地请求总次数</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(l *RetryLimiter)</span></span> GetRetryQuota(succRate <span class="hljs-type">float64</span>, retryProbeNum <span class="hljs-type">int</span>, reqIdx <span class="hljs-type">int</span>) <span class="hljs-type">int</span> &#123;<br><span class="hljs-keyword">if</span> succRate &gt; <span class="hljs-number">0.9</span> &#123;<br><span class="hljs-keyword">if</span> retryProbeNum &gt;= l.CurRetryWindowSize &#123;<br><span class="hljs-comment">// 取当前请求流量1%作为增量，同时min函数确保窗口调整的增量不超过当前窗口大小，保持调整的平稳性</span><br>l.CurRetryWindowSize = l.CurRetryWindowSize + max(min(<span class="hljs-number">1</span>*reqIdx/<span class="hljs-number">100</span>, l.CurRetryWindowSize), <span class="hljs-number">1</span>)<br>&#125;<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>l.CurRetryWindowSize = max(<span class="hljs-number">1</span>, l.CurRetryWindowSize/<span class="hljs-number">2</span>)<br>&#125;<br><br><span class="hljs-keyword">return</span> l.CurRetryWindowSize<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">min</span><span class="hljs-params">(a, b <span class="hljs-type">int</span>)</span></span> <span class="hljs-type">int</span> &#123;<br><span class="hljs-keyword">if</span> a &lt; b &#123;<br><span class="hljs-keyword">return</span> a<br>&#125;<br><span class="hljs-keyword">return</span> b<br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">max</span><span class="hljs-params">(a, b <span class="hljs-type">int</span>)</span></span> <span class="hljs-type">int</span> &#123;<br><span class="hljs-keyword">if</span> a &gt; b &#123;<br><span class="hljs-keyword">return</span> a<br>&#125;<br><span class="hljs-keyword">return</span> b<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br><br>l := RetryLimiter&#123;<br>CurRetryWindowSize: <span class="hljs-number">10</span>,<br>&#125;<br><br><span class="hljs-keyword">for</span> i := <span class="hljs-number">1</span>; i &lt; <span class="hljs-number">100</span>; i++ &#123;<br>succRate := <span class="hljs-type">float64</span>(i) * <span class="hljs-number">0.1</span><br><span class="hljs-keyword">if</span> i &gt; <span class="hljs-number">50</span> &#123;<br>succRate *= <span class="hljs-number">0.1</span><br>&#125;<br><span class="hljs-comment">//retryNum := rand.Int() % 10</span><br>retryProbeNum := rand.Int() % <span class="hljs-number">40</span><br>fmt.Println(<span class="hljs-string">&quot;req:&quot;</span>, i, <span class="hljs-string">&quot;, succRate:&quot;</span>, succRate, <span class="hljs-string">&quot;, get retry quota:&quot;</span>, l.GetRetryQuota(succRate, retryProbeNum, i))<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><h3 id="前端负载均衡"><a href="#前端负载均衡" class="headerlink" title="前端负载均衡"></a>前端负载均衡</h3><p>这部分借鉴自《Google SRE》，主要是通过DNS和Maglev集群去实现分流, 简单来说请求先通过DNS拿到接入层外网ip, 之后发起VIP请求到Maglev节点上(VIP基于keepalive), Maglev也是4层软件负载和LVS类似,有兴趣可以看下<a href="https://www.manjusaka.blog/posts/2020/05/22/a-simple-introduction-about-maglev/index.html">这篇文章</a><br><img src="/images/maglev.png" alt="Google-maglev负载均衡"></p><p>国内用lvs居多，大体也类似:<br><img src="/images/fe_lb.png" alt="前端负载均衡"></p><h3 id="数据中心内负载均衡"><a href="#数据中心内负载均衡" class="headerlink" title="数据中心内负载均衡"></a>数据中心内负载均衡</h3><p><strong>Subset(子集算法限制海量连接)</strong><br>在微服务架构下，服务之间不仅会有“正常的”rpc调用，也会有心跳请求探测依赖服务的存活。问题来了假设当前服务依赖的下游服务很多，并且如果下游又是冗余了多个集群，那么势必需要建立大量的tcp连接(连接数&#x3D;clients*backends)，再加上后续需要会有大量的心跳包，占用了大量cpu资源，面对海量连接client该如何处理?<br><img src="/images/google_subset.png" alt="子集算法"></p><p><strong>常见策略</strong></p><ul><li>轮训</li><li>最少连接数(inflight)</li><li>轮训加权,(成功+，失败-) + cpu使用率</li><li>[the choice of two] (<a href="https://medium.com/the-intuition-project/load-balancing-the-intuition-behind-the-power-of-two-random-choices-6de2e139ac2f">https://medium.com/the-intuition-project/load-balancing-the-intuition-behind-the-power-of-two-random-choices-6de2e139ac2f</a>)</li></ul><p><strong>轮训:</strong><br>理想情况下流量被平均分配之后，下游节点之间的cpu负载差异应该都不相上下，可是实际情况是节点之间的负载差异可能会很大，导致很多资源被浪费，原因如下:</p><ul><li>请求处理成本不一致</li><li>机器资源&#x2F;配置不一致</li><li>性能因素: GC<br>因此轮训在生产环境很少会使用，毕竟真实环境的请求处理成本一定是不均衡的。</li></ul><p><strong>最少连接数(inflight)</strong><br>统计每个连接的inflight请求数, 请求转发到请求最少的节点上。但还是存在请求处理成本的问题，虽然某些节点连接数少，但是万一有个请求成本很高，还是导致负载不均衡。</p><p><strong>加权轮训</strong><br>以上两种负载均衡都是从client端出发，没有从下游负载去考虑，导致下游负载不均。所以轮训加权的实现思路是依据请求<strong>响应结果</strong>[成功&#x2F;失败]以及下游服务<strong>cpu使用率</strong>来动态控制节点权重(cpu使用率是通过rpc回报获取)。</p><p><strong>best of two random choices</strong><br>加权轮训的设计由于“信息滞后”存在“羊群效应”问题，原因有2点, 第一client至少需要1个RTT才能拿到cpu使用率，存在网络、先后请求延迟。第二“定期”更新节点权重。因此client以为拿到了最优节点，但实际请求的是“已经从不饱和变饱和”的节点，导致大量请求超时&#x2F;拒绝。<br>best of two random choices，则采用了带时间衰减的指数衰减(exponentially weighted moving average)[带系数的指数衰减]，引入了inflight，lag作为负载均衡的参考</p><p><img src="/images/two_of_random_choices.png" alt="two_of_random_choices"><br><strong>算法实现</strong><br><a href="https://github.com/go-kratos/kratos/blob/4a93aa9b8d5dca550cc60a0c51c4726f83a2e6f8/pkg/net/rpc/warden/balancer/p2c/p2c.go">B站实现</a><br><img src="/images/two_of_random_choices_algo.png" alt="算法实现"></p><h2 id="分布式限流"><a href="#分布式限流" class="headerlink" title="分布式限流"></a>分布式限流</h2><ul><li>即时消费即时结算</li><li>先消费后结算</li><li>预分配<br>这部分内容就不重复了，直接看<a href="https://codingwhat.github.io/2024/07/09/limiter-in-action/">限流实战</a></li></ul><h2 id="隔离"><a href="#隔离" class="headerlink" title="隔离"></a>隔离</h2><ul><li>动静隔离</li><li>线程隔离</li><li>进程隔离(容器部署)</li><li>租户隔离</li><li>核心隔离</li><li>读写隔离</li><li>热点隔离</li><li>集群隔离</li></ul><h3 id="动静隔离"><a href="#动静隔离" class="headerlink" title="动静隔离"></a>动静隔离</h3><ul><li>静态资源, CDN缓存html、css等静态资源</li><li>动态资源，接口获取</li></ul><h3 id="线程隔离"><a href="#线程隔离" class="headerlink" title="线程隔离"></a>线程隔离</h3><ul><li>java会通过不同线程池处理请求，划分cpu资源</li><li>Go不适用，Go调度模型就会复用线程，无法做隔离，只能控制goroutine个数</li></ul><h3 id="进程隔离"><a href="#进程隔离" class="headerlink" title="进程隔离"></a>进程隔离</h3><ul><li>目前微服务架构基于容器部署，都是独立进程、cpu、内存资源互不影响</li></ul><h3 id="租户隔离"><a href="#租户隔离" class="headerlink" title="租户隔离"></a>租户隔离</h3><ul><li>不同租户请求的不同服务&#x2F;存储</li></ul><h3 id="核心隔离"><a href="#核心隔离" class="headerlink" title="核心隔离"></a>核心隔离</h3><p>核心隔离通常是指将资源按照 <code>核心业务</code> 与 <code>非核心业务</code> 进行划分，优先保障 <code>核心业务</code> 的稳定运行<br>核心&#x2F;非核心故障域的差异隔离（机器资源、依赖资源）  </p><p>核心业务可以搭建多集群通过冗余资源来提升吞吐和容灾能力</p><p>按照服务的核心程度进行分级<br>1级：系统中最关键的服务，如果出现故障会导致用户或业务产生重大损失<br>2级：对于业务非常重要，如果出现故障会导致用户体验受到影响，但不会导致系统完全无法使用<br>3级：会对用户造成较小的影响，不容易注意或很难发现<br>4级：即使失败，也不会对用户体验造成影响  </p><h3 id="读写隔离"><a href="#读写隔离" class="headerlink" title="读写隔离"></a>读写隔离</h3><ul><li>存储读写分离(redis&#x2F;mysql&#x2F;es)</li><li>应用层读写分离，CQRS</li><li>事件驱动，写操作之后发布事件，读服务监听修改</li></ul><h3 id="热点隔离"><a href="#热点隔离" class="headerlink" title="热点隔离"></a>热点隔离</h3><ul><li>实时统计 + 热点识别 + 多级缓存 </li><li>热点监控</li></ul><h3 id="集群隔离"><a href="#集群隔离" class="headerlink" title="集群隔离"></a>集群隔离</h3><p>每个服务部署独立的集群</p><h1 id="外部工具"><a href="#外部工具" class="headerlink" title="外部工具"></a>外部工具</h1><h2 id="混沌工程"><a href="#混沌工程" class="headerlink" title="混沌工程"></a>混沌工程</h2><p>通过注入cpu高负载、网络超时等故障，主动找出系统中薄弱环节</p><h2 id="全链路压测"><a href="#全链路压测" class="headerlink" title="全链路压测"></a>全链路压测</h2><p>生产环境模拟真实用户压测, 提前发现隐藏问题。<br>压测过程：压测流量构建 -&gt; 流量染色(隔离, 影子库(redis&#x2F;mysql)) -&gt; 压测引擎启动  -&gt; 可视化监控</p><p>如果你司没有自研平台，也可以用云厂商提供的。<br><strong>故障演练</strong><br><a href="https://cloud.tencent.com/product/cfg">腾讯云混沌工程</a><br><a href="https://www.aliyun.com/product/aliware/ahas/chaos?spm=5176.21213303.J_qCOwPWspKEuWcmp8qiZNQ.17.7da82f3dazso4O&scm=20140722.S_product@@%E4%BA%91%E4%BA%A7%E5%93%81@@1157223._.ID_product@@%E4%BA%91%E4%BA%A7%E5%93%81@@1157223-RL_%E6%B7%B7%E6%B2%8C%E5%B7%A5%E7%A8%8B-LOC_llm-OR_ser-V_3-RE_new4@@cardOld-P0_1">阿里云Chaos</a></p><p><strong>全链路压测</strong><br><a href="https://cloud.tencent.com/product/pts">腾讯云-PTS</a><br><a href="https://www.aliyun.com/product/pts?spm=5176.21213303.J_qCOwPWspKEuWcmp8qiZNQ.20.13fc2f3dkx6uFr&scm=20140722.S_card@@%E4%BA%A7%E5%93%81@@596788.S_card0.ID_card@@%E4%BA%A7%E5%93%81@@596788-RL_%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B-LOC_search~UND~card~UND~item-OR_ser-V_3-RE_cardOld-P0_0">阿里云-PTS</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>GO</tag>
      
      <tag>可用性治理</tag>
      
      <tag>微服务</tag>
      
      <tag>服务可用性</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Single-flight 核心逻辑拆解</title>
    <link href="/2024/07/17/single-flight-analysis/"/>
    <url>/2024/07/17/single-flight-analysis/</url>
    
    <content type="html"><![CDATA[<p>业务场景中经常会有缓存的身影，虽然缓存给我们带来了诸多好处，但是缓存带来的问题却不容小觑，常见的有缓存雪崩、缓存穿透、缓存击穿。 今天来说说缓存击穿及其解决方案。</p><h2 id="问题场景"><a href="#问题场景" class="headerlink" title="问题场景"></a>问题场景</h2><p>当发生缓存击穿时，瞬时流量会涌入下游服务或者存储造成极大的冲击甚至打挂，此时业务应该如何应对？</p><span id="more"></span><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案:"></a>解决方案:</h2><p>singleflight, 主要解决了:</p><ol><li>流量合并，将N个请求-&gt;1个请求</li><li>流量拦截，如果发现已经有inflight请求，会阻塞等待inflight请求返回结果</li></ol><h3 id="核心逻辑"><a href="#核心逻辑" class="headerlink" title="核心逻辑"></a>核心逻辑</h3><ul><li><p>抽象同类请求，利用wg去控制阻塞</p><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs gauss"><span class="hljs-built_in">type</span> <span class="hljs-keyword">call</span> <span class="hljs-keyword">struct</span> &#123;<br>wg sync.WaitGroup <span class="hljs-comment">//利用其Wait 阻塞请求</span><br><br>val interface&#123;&#125; <span class="hljs-comment">// 返回结果，被阻塞请求需要</span><br><br>    <span class="hljs-meta">## 省略非核心字段</span><br>&#125;<br><br></code></pre></td></tr></table></figure></li><li><p>保存全局瞬时请求</p><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs gauss"><span class="hljs-built_in">type</span> Group <span class="hljs-keyword">struct</span> &#123;<br>mu sync.Mutex       <span class="hljs-comment">// protects m</span><br>m  map[<span class="hljs-keyword">string</span>]*<span class="hljs-keyword">call</span> <span class="hljs-comment">// 保存全局请求，lazily initialized</span><br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>核心函数Do</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(g *Group)</span></span> Do(key <span class="hljs-type">string</span>, fn <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> (<span class="hljs-keyword">interface</span>&#123;&#125;, <span class="hljs-type">error</span>)) (v <span class="hljs-keyword">interface</span>&#123;&#125;, err <span class="hljs-type">error</span>, shared <span class="hljs-type">bool</span>) &#123;<br>g.mu.Lock()<br><span class="hljs-keyword">if</span> g.m == <span class="hljs-literal">nil</span> &#123;<br>g.m = <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]*call)<br>&#125;<br><span class="hljs-keyword">if</span> c, ok := g.m[key]; ok &#123;<br>c.dups++<br>g.mu.Unlock()<br>## 一旦发现有请求，就在这阻塞，注意使用了wg<br>c.wg.Wait()<br><br>#<span class="hljs-keyword">if</span> e, ok := c.err.(*panicError); ok &#123;<br>#<span class="hljs-built_in">panic</span>(e)<br>#&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> c.err == errGoexit &#123;<br>#runtime.Goexit()<br>#&#125;<br><span class="hljs-keyword">return</span> c.val, c.err, <span class="hljs-literal">true</span><br>&#125;<br>c := <span class="hljs-built_in">new</span>(call)<br>c.wg.Add(<span class="hljs-number">1</span>)<br>g.m[key] = c<br>g.mu.Unlock()<br><br>g.doCall(c, key, fn)<br><span class="hljs-keyword">return</span> c.val, c.err, c.dups &gt; <span class="hljs-number">0</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(g *Group)</span></span> doCall(c *call, key <span class="hljs-type">string</span>, fn <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> (<span class="hljs-keyword">interface</span>&#123;&#125;, <span class="hljs-type">error</span>)) &#123;<br><span class="hljs-comment">// use double-defer to distinguish panic from runtime.Goexit,</span><br><span class="hljs-comment">// more details see https://golang.org/cl/134395</span><br><span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-comment">// the given function invoked runtime.Goexit</span><br><span class="hljs-keyword">if</span> !normalReturn &amp;&amp; !recovered &#123;<br>c.err = errGoexit<br>&#125;<br><br>g.mu.Lock()<br><span class="hljs-keyword">defer</span> g.mu.Unlock()<br>c.wg.Done()<br><span class="hljs-keyword">if</span> g.m[key] == c &#123;<br><span class="hljs-built_in">delete</span>(g.m, key)<br>&#125;<br>        .... 省略<span class="hljs-built_in">panic</span>/channel相关处理<br>&#125;()<br>    .... 省略非核心代码<br>c.val, c.err = fn()<br>    ...  省略非核心代码<br><br><span class="hljs-keyword">if</span> !normalReturn &#123;<br>recovered = <span class="hljs-literal">true</span><br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure></li></ul><h3 id="自己动手实践"><a href="#自己动手实践" class="headerlink" title="自己动手实践"></a>自己动手实践</h3><p>tips:<br>为了理解singleflight的设计思想，在实践过程中省去了非核心逻辑, 只关注核心数据结构。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;fmt&quot;</span><br><span class="hljs-string">&quot;sync&quot;</span><br><span class="hljs-string">&quot;sync/atomic&quot;</span><br><span class="hljs-string">&quot;time&quot;</span><br>)<br><br><span class="hljs-keyword">type</span> HandleFn <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> (<span class="hljs-keyword">interface</span>&#123;&#125;, <span class="hljs-type">error</span>)<br><br><span class="hljs-keyword">type</span> call <span class="hljs-keyword">struct</span> &#123;<br>sync.WaitGroup<br>val <span class="hljs-keyword">interface</span>&#123;&#125;<br>err <span class="hljs-type">error</span><br>&#125;<br><br><span class="hljs-keyword">var</span> (<br>groups = <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]*call)<br>mu     sync.RWMutex<br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">var</span> wg sync.WaitGroup<br>num := <span class="hljs-number">5</span><br>wg.Add(num)<br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; num; i++ &#123;<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(gid <span class="hljs-type">int</span>)</span></span> &#123;<br><span class="hljs-keyword">defer</span> wg.Done()<br>v, err := Do(<span class="hljs-string">&quot;key1&quot;</span>, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> (<span class="hljs-keyword">interface</span>&#123;&#125;, <span class="hljs-type">error</span>) &#123;<br>queryDB(gid)<br><span class="hljs-keyword">return</span> time.Now().Unix(), <span class="hljs-literal">nil</span><br>&#125;)<br>fmt.Println(<span class="hljs-string">&quot;Goroutine:&quot;</span>, gid, <span class="hljs-string">&quot;----&gt; get data &quot;</span>, v, err)<br>&#125;(i)<br>&#125;<br>wg.Wait()<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">queryDB</span><span class="hljs-params">(gid <span class="hljs-type">int</span>)</span></span> &#123;<br><span class="hljs-comment">// 模拟查询DB</span><br>time.Sleep(<span class="hljs-number">1</span> * time.Second)<br>fmt.Println(<span class="hljs-string">&quot;Goroutine:&quot;</span>, gid, <span class="hljs-string">&quot;---&gt; querying DB .... &quot;</span>)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Do</span><span class="hljs-params">(key <span class="hljs-type">string</span>, fn HandleFn)</span></span> (<span class="hljs-keyword">interface</span>&#123;&#125;, <span class="hljs-type">error</span>) &#123;<br>mu.Lock()<br>w, ok := groups[key]<br><span class="hljs-keyword">if</span> ok &#123;<br>mu.Unlock()<br>w.Wait()<br><span class="hljs-keyword">return</span> w.val, w.err<br>&#125;<br>c := <span class="hljs-built_in">new</span>(call)<br>c.Add(<span class="hljs-number">1</span>)<br>groups[key] = c<br>mu.Unlock()<br><br>fmt.Println(<span class="hljs-string">&quot;---&gt;call&quot;</span>)<br>c.val, c.err = fn()<br><br>mu.Lock()<br>c.Done()<br><span class="hljs-built_in">delete</span>(groups, key)<br>mu.Unlock()<br><br><span class="hljs-keyword">return</span> c.val, c.err<br>&#125;<br><br></code></pre></td></tr></table></figure><p>输出结果:</p><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs xl">---&gt;call<br>G<span class="hljs-function"><span class="hljs-title">oroutine</span>: 0 ---&gt;</span> querying DB .... <br>G<span class="hljs-function"><span class="hljs-title">oroutine</span>: 2 ----&gt;</span> get <span class="hljs-keyword">data</span>  <span class="hljs-number">1721205160</span> &lt;<span class="hljs-literal">nil</span>&gt;<br>G<span class="hljs-function"><span class="hljs-title">oroutine</span>: 0 ----&gt;</span> get <span class="hljs-keyword">data</span>  <span class="hljs-number">1721205160</span> &lt;<span class="hljs-literal">nil</span>&gt;<br>G<span class="hljs-function"><span class="hljs-title">oroutine</span>: 1 ----&gt;</span> get <span class="hljs-keyword">data</span>  <span class="hljs-number">1721205160</span> &lt;<span class="hljs-literal">nil</span>&gt;<br>G<span class="hljs-function"><span class="hljs-title">oroutine</span>: 4 ----&gt;</span> get <span class="hljs-keyword">data</span>  <span class="hljs-number">1721205160</span> &lt;<span class="hljs-literal">nil</span>&gt;<br>G<span class="hljs-function"><span class="hljs-title">oroutine</span>: 3 ----&gt;</span> get <span class="hljs-keyword">data</span>  <span class="hljs-number">1721205160</span> &lt;<span class="hljs-literal">nil</span>&gt;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>GO</tag>
      
      <tag>缓存击穿</tag>
      
      <tag>缓存问题</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>限流实战</title>
    <link href="/2024/07/09/limiter-in-action/"/>
    <url>/2024/07/09/limiter-in-action/</url>
    
    <content type="html"><![CDATA[<blockquote><p>有经验的开发者都知道即便事前做了不同规模的容量模型，但是还是没办法准确预测未知的外部流量，因此服务必须得采取自保护策略，丢弃掉部分流量来保障服务的稳定性。</p></blockquote><span id="more"></span><p>接下来我们会围绕静态、动态以及集群限流去讲解限流在不同场景下的工程实践。</p><h1 id="静态限流"><a href="#静态限流" class="headerlink" title="静态限流"></a>静态限流</h1><p><a href="golang.org/x/time/rate">标准库-令牌桶</a>, 应对小规模突发流量;<br><a href="https://github.com/uber-go/ratelimit">Uber-漏桶</a>, 匀速限流; 突发流量丢弃量多; !!这个库(v0.3.0)有bug<a href="https://colobu.com/2023/12/05/two-bugs-of-uber-ratelimit/">点击</a><br>滑动窗口, 精度高; 占用内存<br>固定窗口, 实现简单; 不精准，存在边界问题</p><p>总结:</p><ul><li>实现简单</li><li>基于QPS限流静态限流, 无法根据服务的负载动态限流  </li><li>限流阈值不好配置(请求的处理成本不一致)  </li><li>节点扩缩, 需要重新设置</li></ul><h2 id="动手实践-令牌桶"><a href="#动手实践-令牌桶" class="headerlink" title="动手实践-令牌桶"></a>动手实践-令牌桶</h2><p>核心逻辑源自标准库的rate包</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> TokenBucket <span class="hljs-keyword">struct</span> &#123;<br>rate       <span class="hljs-type">float64</span>    <span class="hljs-comment">// 令牌添加到桶中的速率。</span><br>burst      <span class="hljs-type">int</span>        <span class="hljs-comment">// 桶的最大容量。</span><br>tokens     <span class="hljs-type">float64</span>    <span class="hljs-comment">// 当前桶中的令牌数量。</span><br>lastUpdate time.Time  <span class="hljs-comment">// 上次更新令牌数量的时间。</span><br>mu         sync.Mutex <span class="hljs-comment">// 互斥锁，确保线程安全。</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(tb *TokenBucket)</span></span> tokensFromDuration(d time.Duration) <span class="hljs-type">float64</span> &#123;<br><span class="hljs-comment">// Split the integer and fractional parts ourself to minimize rounding errors.</span><br><span class="hljs-comment">// See golang.org/issues/34861.</span><br>sec := <span class="hljs-type">float64</span>(d/time.Second) * tb.rate<br>nsec := <span class="hljs-type">float64</span>(d%time.Second) * tb.rate<br><span class="hljs-keyword">return</span> sec + nsec/<span class="hljs-number">1e9</span><br>&#125;<br><br><span class="hljs-comment">// NewTokenBucket 创建一个新的令牌桶，给定令牌添加速率和桶的容量。</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewTokenBucket</span><span class="hljs-params">(rate <span class="hljs-type">float64</span>, b <span class="hljs-type">int</span>)</span></span> *TokenBucket &#123;<br><span class="hljs-keyword">return</span> &amp;TokenBucket&#123;<br>rate:   rate,<br>burst:  b,<br>tokens: <span class="hljs-number">0</span>,<br>&#125;<br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(tb *TokenBucket)</span></span> durationFromTokens(tokens <span class="hljs-type">float64</span>) time.Duration &#123;<br>seconds := tokens / tb.rate<br><span class="hljs-keyword">return</span> time.Nanosecond * time.Duration(<span class="hljs-number">1e9</span>*seconds)<br>&#125;<br><br><span class="hljs-comment">// Allow 检查是否可以从桶中取出一个令牌。如果可以，它取出一个令牌并返回 true。</span><br><span class="hljs-comment">// 如果不可以，它返回 false。</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(tb *TokenBucket)</span></span> Allow() <span class="hljs-type">bool</span> &#123;<br>tb.mu.Lock()<br><span class="hljs-keyword">defer</span> tb.mu.Unlock()<br><br>now := time.Now()<br><span class="hljs-comment">// 计算（可生成令牌数)所需要的时间，burst令牌桶容量，tokens: 当前存在的令牌个数</span><br>maxElapsed := tb.durationFromTokens(<span class="hljs-type">float64</span>(tb.burst) - tb.tokens)<br>elapsed := now.Sub(tb.lastUpdate)<br><span class="hljs-keyword">if</span> elapsed &gt; maxElapsed &#123;<br>elapsed = maxElapsed<br>&#125;<br><br><span class="hljs-comment">// 计算生成的令牌</span><br>delta := tb.tokensFromDuration(elapsed)<br>tokens := tb.tokens + delta<br><span class="hljs-keyword">if</span> burst := <span class="hljs-type">float64</span>(tb.burst); tokens &gt; burst &#123;<br>tokens = burst<br>&#125;<br>tokens--<br><span class="hljs-keyword">var</span> waitDuration time.Duration<br><span class="hljs-keyword">if</span> tokens &lt; <span class="hljs-number">0</span> &#123;<br><span class="hljs-comment">//说明取不到1个token, 那就计算取到1个token所需要的等待时间</span><br>waitDuration = tb.durationFromTokens(-tokens)<br>&#125;<br>ok := <span class="hljs-number">1</span> &lt;= tb.burst &amp;&amp; waitDuration &lt;= <span class="hljs-number">0</span><br><span class="hljs-keyword">if</span> ok &#123;<br>tb.lastUpdate = now<br>tb.tokens = tokens<br>&#125;<br><span class="hljs-keyword">return</span> ok<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>tokenBucket := NewTokenBucket(<span class="hljs-number">2.0</span>, <span class="hljs-number">1.0</span>)<br>      success := <span class="hljs-number">0</span><br>      reject := <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-keyword">if</span> tokenBucket.Allow() &#123;<br>fmt.Println(time.Now().Format(<span class="hljs-string">&quot;15:04:05&quot;</span>), <span class="hljs-string">&quot;, 请求通过\n&quot;</span>)<br>success++<br>&#125;<span class="hljs-keyword">else</span> &#123;<br>    reject++<br>&#125;<br>&#125;<br><br>fmt.Println(success, <span class="hljs-string">&quot;&lt;======&gt;&quot;</span>, reject)<br>&#125;<br></code></pre></td></tr></table></figure><p>tips:<br>Sleep精准问题有兴趣可以看看[这篇文章](<a href="https://colobu.com/2023/12/07/more-precise-sleep/%EF%BC%89">https://colobu.com/2023/12/07/more-precise-sleep/）</a></p><h1 id="动态限流"><a href="#动态限流" class="headerlink" title="动态限流"></a>动态限流</h1><p>通过实例的负载情况(采样窗口内的cpu使用率&#x2F;load1)进行动态设置限流阈值，让服务保持高水位高效运行。</p><h2 id="开源实现"><a href="#开源实现" class="headerlink" title="开源实现"></a>开源实现</h2><p><a href="https://github.com/go-kratos/aegis/tree/main/ratelimit/bbr">B站-BBR</a><br><a href="https://github.com/alibaba/sentinel-golang/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E6%B5%81%E6%8E%A7">sentinel-go</a><br><a href="https://queue.acm.org/appendices/codel.html">Co-DEL</a><br><a href="https://github.com/go-kratos/kratos/blob/4a93aa9b8d5dca550cc60a0c51c4726f83a2e6f8/pkg/container/queue/aqm/codel.go">B站-Codel</a></p><h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><p>1.B站-BBR: 使用滑动窗口统计成功数、响应时间；通过滑窗计算平均响应时间，根据利特尔法则计算QPS，当CPU使用率满足阈值时，动态设置限流阈值。<br><code>QPS = (MaxPass(窗口内最大成功请求数) * MinRt(平均响应延时:ms) * BucketsPerSecond(1s的桶个数) /1000.0)</code></p><p>2.Sentinel-go: 原理和B站类似，不过使用时load1(实时性较较差, 1分钟内的负载)<br>3.Co-DEL: 传统FIFO在海量请求场景下会出现大量请求“饿死”的情况, 而codel很好的规避了这个问题，codel会清理超时请求并且自动拒绝。<a href="https://github.com/LyricTian/kratos/blob/bd2d576848f44f7bf4eb7c9420b36093fa4f8ef7/pkg/container/queue/aqm/codel.go">B站的实现</a>有2个容忍窗口, 容忍窗口期间请求还是会被放行, 超过窗口的才会被拒绝。</p><p>总结</p><ul><li>精确限流, 动态调整阈值, 和服务负载正相关; 但是实现复杂，需要额外资源统计CPU使用率、QPS吞吐等; 限于接口调用，场景少</li><li>请求分优先级(用户纬度)，可按优先级丢弃、可以存在一定超卖。</li><li>拒绝请求也需要成本, cliet端需要截流(直接往上抛或者重试其他节点)</li></ul><h2 id="客户端节流"><a href="#客户端节流" class="headerlink" title="客户端节流"></a>客户端节流</h2><p>主要有以下两种场景<br>1.用户客户端疯狂重试；客户端需要随机退避重试<br>2.下游过载, 返回”超出配额，拒绝请求”; 主调可以按概率拒绝请求; <a href="https://sre.google/sre-book/handling-overload/">算法</a><br><img src="/images/adaptive_throttling.png" alt="自适应限流"></p><h1 id="集群限流"><a href="#集群限流" class="headerlink" title="集群限流"></a>集群限流</h1><p>为什么要用集群限流？在分布式场景下单机限流有2个缺陷：</p><ul><li>当限流配额&gt;节点数，单机限流就不能限制了；比如100个节点，50QPS，此时更适合集群限流</li><li>当流量不均时，单机限流会出现误限; 比如50个节点，100QPS，此时单节点2QPS，但如果流量不均，没达到阈值就拒绝请求了</li></ul><h2 id="限流模式"><a href="#限流模式" class="headerlink" title="限流模式"></a>限流模式</h2><ul><li>单次分配，即时消费即时结算</li><li>批次分配，先消费后结算</li><li>批次分配，预先分配消费</li></ul><h3 id="单次分配-即时消费即时结算-强一致"><a href="#单次分配-即时消费即时结算-强一致" class="headerlink" title="单次分配 即时消费即时结算 强一致"></a><font color="green">单次分配</font> 即时消费即时结算 强一致</h3><ul><li>精准限流，会增加业务延迟</li><li>基于redis,sentinel实现</li><li>秒杀等对精准性要求较高的细粒度限流</li></ul><h3 id="批次分配-最终一致-性能高，但准确性会降低"><a href="#批次分配-最终一致-性能高，但准确性会降低" class="headerlink" title="批次分配  最终一致, 性能高，但准确性会降低"></a><font color="green">批次分配</font>  最终一致, 性能高，但准确性会降低</h3><p><font color="black">实现原理:</font><br><font color="orange">本地异步请求限流服务获取配额(quota)，本地采用静态限流算法</font></p><p>一般都是客户端(LRU窗口)限流 + 客户端定期上报(ms级)配额到限流器 + 限流器响应客户端剩余配额 + 客户端重新计算限流额</p><ul><li>预分配后消费; Youtube doorman; 本地限流，如果流量不均会有误限;适用服务级限流，读写分离的接口级限流</li><li>先消费后结算; 阿里AHAS; 客户端基于剩余整体配额进行扣除，不再进行均摊，解决误限问题，但可能会有超限; 服务&#x2F;接口限流等允许一定误差的限流场景</li></ul><p>先消费后结算:</p><ol><li>client异步定期(30ms)同步限流server结算,</li><li>请求一致性hash到对应的限流server上，</li><li>限流server下发所有剩余配额</li></ol><p>存在问题:<br>假设10个client,QPS限流1000， 每个节点QPS：100, 在30ms内消耗了100配额，实际放行请求: 10 * 1000个请求。<br>优化：</p><ul><li>调整上报周期，降低周期+周期随机化(防止上报风暴)</li><li>每个窗口都单独上报, 性能有损, 对hash到同一节点的窗口合并批量上报</li><li>同步限流集群失败，降级为单机限流，总配额&#x2F;客户端数(client)</li></ul><p><a href="https://sentinelguard.io/zh-cn/docs/cluster-flow-control.html">setinel</a>集群限流(云上版本 AHAS Sentinel)</p><p><img src="/images/sentinel_limit_center.png" alt="集中式"><br><img src="/images/sentinel_limit_embedded.png" alt="嵌入式"></p><h2 id="限流策略"><a href="#限流策略" class="headerlink" title="限流策略"></a>限流策略</h2><ul><li>多级限流(网关层、应用层、服务层、数据层)</li><li>动态阈值调整(负载高降低权重)</li><li>多级维度(ip,设备) + 业务侧规则(发评限制)</li></ul><h2 id="重要性-服务分级"><a href="#重要性-服务分级" class="headerlink" title="重要性-服务分级"></a>重要性-服务分级</h2><p>在对服务进行限流时，可以引入更细的粒度-<strong>Criticality</strong>来按优先级丢弃流量,<br>CRITICAL_PLUS, 最高优先级，影响面:用户可见，严重；容量设置需充足<br>CRITICAL, 次优先级，影响面:用户可见，不如Plus严重；容量设置需充足<br>SHEDDABLE_PLUS, 异步任务，可定期重试<br>SHEDDABLE，最低优先级，接受不可用</p><p><font color="red">Criticality 应该在服务调用链中逐级传递下去。</font></p>]]></content>
    
    
    
    <tags>
      
      <tag>GO</tag>
      
      <tag>可用性治理</tag>
      
      <tag>限流</tag>
      
      <tag>单机限流</tag>
      
      <tag>集群限流</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>go_nginx_502问题排查</title>
    <link href="/2024/07/09/go-nginx-502/"/>
    <url>/2024/07/09/go-nginx-502/</url>
    
    <content type="html"><![CDATA[<blockquote><p>线上巡检发现很多502日志，于是就开始了漫漫debug</p></blockquote><span id="more"></span><p>简单介绍背景</p><ol><li>线上服务:</li></ol><ul><li>容器部署</li><li>http</li><li>Nginx + Go</li><li>服务耗时基本在100ms左右</li></ul><ol start="2"><li>已做排查，排除服务不可用导致的502问题</li></ol><ul><li>服务是否重启</li><li>容器是否异常、重启</li><li>磁盘、cpu是否异常</li></ul><h2 id="问题现场"><a href="#问题现场" class="headerlink" title="问题现场"></a>问题现场</h2><h3 id="问题1-upstream-prematurely-closed-connection"><a href="#问题1-upstream-prematurely-closed-connection" class="headerlink" title="问题1: upstream prematurely closed connection"></a>问题1: upstream prematurely closed connection</h3><p>在排查nginx日志时发现如下错误</p><blockquote><p>nginx error log: “upstream prematurely closed connection while reading response header from upstream”</p></blockquote><p>很明显服务主动关闭了连接，httpServer主动关闭连接一般是read&#x2F;write超时了, 但是查看服务配置发现read&#x2F;write分别1s&#x2F;3s, 并且服务逻辑中都有严格的超时控制、没有阻塞逻辑，讲道理不太可能触发，所以这里排除。问题到这里似乎进到死胡同了，这时在看server源码是发现<font color="red">idletimeout</font>这个配置, 如果没有设置默认取read timeout，经google之后发现就是keepalive的timeout。我们知道http&#x2F;1.1默认都是keepalive的, 如果触发了keepalive timeout, server会主动关闭连接，于是开始抓包分析(如下图)，发现go服务在1s之后主动断开了和nginx的连接。</p><p><img src="/images/wireshark_502.png" alt="img.png"></p><p>这里总结下整个请求链路.<br>首先nginx和upstream server(go 服务)之间会创建多个连接；外部请求进来以后, nginx作为client端，从连接池获取一个连接请求，如果此时刚好这个连接keepalive timeout了那么就会触发502。</p><p>问题解决:</p><ol><li>nginx proxy设置keepalive;<br><code>proxy_http_version 1.1</code> 、 <code>proxy_set_header Connection &quot;&quot;</code><br>upstream不需要外部请求Connection控制，直接清空<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-section">location</span> / &#123;<br>        <span class="hljs-attribute">proxy_pass</span> xxxx;<br>        <br>        <span class="hljs-comment"># !!!!! start </span><br>        <span class="hljs-attribute">proxy_http_version</span> <span class="hljs-number">1</span>.<span class="hljs-number">1</span>;<br>        <span class="hljs-attribute">proxy_set_header</span> Connection <span class="hljs-string">&quot;&quot;</span>;<br>         <span class="hljs-comment"># !!!!! end </span><br>        <span class="hljs-comment">#proxy_read_timeout     300;    </span><br>        <span class="hljs-comment">#proxy_connect_timeout  300;</span><br>        <span class="hljs-comment">#proxy_set_header X-Real-IP $remote_addr;</span><br>        <span class="hljs-comment"># needed for HTTPS</span><br>        <span class="hljs-comment"># # proxy_set_header X_FORWARDED_PROTO https;</span><br>        <span class="hljs-comment">#proxy_set_header X-Forwarded-For $remote_addr;</span><br>        <span class="hljs-comment">#proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</span><br>        <span class="hljs-comment">#proxy_set_header Host $host;</span><br>&#125;<br></code></pre></td></tr></table></figure></li><li>nginx.conf设置keepalive timeout<br>这里时nginx和外部请求的keepalive, 如果超过这时间nginx会关闭连接。<figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs abnf">keepalive_timeout  <span class="hljs-number">60</span>s<span class="hljs-comment">;</span><br></code></pre></td></tr></table></figure></li><li>upstream server设置keepalive timeout<figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs lasso">&amp;http.Server&#123;<br>#Addr: addr,<br>#Handler:    http.HandlerFunc(ServeHTTP),<br>#ReadTimeout:  time.<span class="hljs-built_in">Duration</span>(httpRunner.ReadTimeout) * time.Second,<br>#WriteTimeout: time.<span class="hljs-built_in">Duration</span>(httpRunner.WriteTimeout) * time.Second,<br><span class="hljs-params">...</span><br>IdleTimeout:  time.<span class="hljs-built_in">Duration</span>(httpRunner.IdleTimeout) * time.Second,<br><span class="hljs-params">...</span><br>#ConnState:    httpRunner.connState,<br>#ErrorLog:     syslog.<span class="hljs-literal">New</span>(httpErrorLog&#123;logger&#125;, <span class="hljs-string">&quot;&quot;</span>, <span class="hljs-number">0</span>),<br>&#125;<br></code></pre></td></tr></table></figure></li></ol><h3 id="问题2-listen-backlog-过低"><a href="#问题2-listen-backlog-过低" class="headerlink" title="问题2: listen backlog 过低"></a>问题2: listen backlog 过低</h3><p>在对服务进行压测时，发现请求如果走nginx会发生阻塞，而直接压测服务却能正常运行，此时发现nginx日志有大量502</p><p>问题解决:</p><ol><li>listen backlog用了默认长度511, listen backlog是长连接队列长度，如果长度过短，容易打满拒绝请求，将backlog长度调大，能进一步提升吞吐。</li><li>注意全局长连接队列限制 <code>/proc/sys/net/core/somaxconn</code> 也得调整，<code>nginx backlog</code> &lt;&#x3D; <code>somaxconn</code></li></ol><h3 id="问题3-暴力清理nginx日志"><a href="#问题3-暴力清理nginx日志" class="headerlink" title="问题3: 暴力清理nginx日志"></a>问题3: 暴力清理nginx日志</h3><p>通过keepalive配置，502问题确实明显改善了，但是突然过了几天，又偶现了502问题，在排查基础资源监控时发现502的时间点，恰好有磁盘和内存空间骤降；<br>这里定位是因为反向代理的nginx会记录access日志，而我们的服务流量很高access日志容易写满，需要定时清理，清理逻辑：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># crontab</span><br><span class="hljs-built_in">echo</span> &gt; /path/access.log<br></code></pre></td></tr></table></figure><p>这里有个背景说明下:<br>access文件是会被采集程序访问上报到日志平台。上述直接”echo &gt; “ 是可能会导致os.Cache中日志被清理,可能采集程序就会采集不到，出现异常。</p><p>改造逻辑: </p><ul><li>logrotate 10G切割，只保留1个备份文件</li><li>备份文件会等段时间才被清理(当前10min), 保证采集程序能采集成功</li></ul><p>当然也可以自己写逻辑:</p><ol><li>按access.log 10g为切割</li><li>历史文件不会立即被清理会，等待10min，保证采集程序能采集成功</li><li>kill -USR1 nginxpid, 命令nginx重新加载配置。<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-attribute">file_path</span>=<span class="hljs-string">&quot;/path/&quot;</span><br><span class="hljs-attribute">log_file</span>=<span class="hljs-string">&quot;access.log&quot;</span><br><span class="hljs-comment">#nginx进程id</span><br><span class="hljs-attribute">nginx_pid</span>=<span class="hljs-string">&quot;/path/nginx.pid &quot;</span><br><span class="hljs-comment">#单位:G</span><br><span class="hljs-attribute">max_log_size</span>=10<br><span class="hljs-comment"># 备份日志最长存活时间 单位:s</span><br><span class="hljs-attribute">max_log_ttl</span>=300<br><br><br><span class="hljs-attribute">timestamp</span>=$(date +%s)<br><span class="hljs-attribute">log_back_file</span>=<span class="hljs-string">&quot;<span class="hljs-variable">$file_path</span><span class="hljs-variable">$log_file</span>-bak-<span class="hljs-variable">$timestamp</span>&quot;</span><br><span class="hljs-comment"># 获取文件大小（以字节为单位）</span><br><span class="hljs-attribute">file_size</span>=$(stat -c <span class="hljs-string">&quot;%s&quot;</span> <span class="hljs-string">&quot;<span class="hljs-variable">$file_path</span><span class="hljs-variable">$log_file</span>&quot;</span>)<br><span class="hljs-attribute">file_size_gb</span>=$(echo <span class="hljs-string">&quot;scale=2; <span class="hljs-variable">$file_size</span> / 1024^3&quot;</span> | bc)<br><span class="hljs-comment"># 判断文件大小是否超过10G</span><br><span class="hljs-keyword">if</span> (( $(echo <span class="hljs-string">&quot;<span class="hljs-variable">$file_size_gb</span> &gt; <span class="hljs-variable">$max_log_size</span> &quot;</span> | bc -l) )); then<br>    mv <span class="hljs-variable">$file_path</span><span class="hljs-variable">$log_file</span>  <span class="hljs-variable">$log_back_file</span><br>    cat <span class="hljs-variable">$nginx_pid</span> | xargs kill -USR1<br>fi<br><br><span class="hljs-comment"># 遍历当前目录下的所有文件</span><br><span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> <span class="hljs-string">&quot;<span class="hljs-variable">$file_path</span>/<span class="hljs-variable">$log_file</span>&quot;</span>-bak-*; <span class="hljs-keyword">do</span><br>    # 检查文件是否为普通文件并且修改时间超过10分钟<br>    <span class="hljs-keyword">if</span> [[ -f <span class="hljs-string">&quot;<span class="hljs-variable">$file</span>&quot;</span> &amp;&amp; $(($(date +%s) - $(stat -c %Y <span class="hljs-string">&quot;<span class="hljs-variable">$file</span>&quot;</span>))) -gt <span class="hljs-variable">$max_log_ttl</span> ]]; then<br>        # 删除文件<br>        rm <span class="hljs-string">&quot;<span class="hljs-variable">$file</span>&quot;</span><br>        echo <span class="hljs-string">&quot;已删除文件: <span class="hljs-variable">$file</span>&quot;</span><br>    fi<br>done<br></code></pre></td></tr></table></figure></li></ol><h3 id="优化成果"><a href="#优化成果" class="headerlink" title="优化成果"></a>优化成果</h3><p>之前每天必复现, 连续一周未收到告警<br><img src="/../images/now_502.png" alt="img.png"></p>]]></content>
    
    
    
    <tags>
      
      <tag>Go</tag>
      
      <tag>Nginx</tag>
      
      <tag>502</tag>
      
      <tag>keepalive</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>你了解GoGC么？</title>
    <link href="/2024/07/08/Understating_GoGC/"/>
    <url>/2024/07/08/Understating_GoGC/</url>
    
    <content type="html"><![CDATA[<blockquote><p>“你了解GC么？” 好多面试官都爱问这种“简单”问题😅，如果平常没有积累，在那种高压下我想大部分人跟我一样大脑空白、 支支吾吾, 处于已读乱回的状态。<br>其实这类问题就是典型的”冰山模型”，看似很简单一问，实际需要考虑的细节很多，很容易答不好。今天我就尝试来回答这个问题，也算是对自己学习GC的一个阶段性总结。</p></blockquote><span id="more"></span><h1 id="GC演进历史"><a href="#GC演进历史" class="headerlink" title="GC演进历史"></a>GC演进历史</h1><p>关键节点:</p><ul><li>Go1.8：引入混合写屏障</li><li>Go1.17: 采用内存归还策略:MADV_DONTNEED(立即归还), 在这之前是MADV_FREE(延迟归还，会导致内存误报)<br>详细可以看:<br><a href="https://www.topgoer.cn/docs/goquestions/goquestions-1cjh5mftsd3dm">https://www.topgoer.cn/docs/goquestions/goquestions-1cjh5mftsd3dm</a></li></ul><h1 id="GC原理"><a href="#GC原理" class="headerlink" title="GC原理"></a>GC原理</h1><p>GC主要分为两部分</p><ul><li>mutator, 用户态的代码，对GC来说就是做引用的插入或删除，所以叫赋值器</li><li>collector, 垃圾回收器, 扫描+清理。<br>Go在1.8之前是基于三色标记和插入屏障来回收垃圾对象，之后引入了混合写屏障，消除了插入屏障在栈空间的重扫和STW损耗，在性能上有了进一步提升。</li></ul><h2 id="GC触发时机"><a href="#GC触发时机" class="headerlink" title="GC触发时机:"></a>GC触发时机:</h2><ul><li>定时调用: sysmon线程定期执行, 依据是否满足debug.SetGCPercent阈值执行gc</li><li>申请堆空间时调用: mallocgc</li><li>手动触发: runtime.GC()</li></ul><h2 id="三色标记算法"><a href="#三色标记算法" class="headerlink" title="三色标记算法"></a>三色标记算法</h2><p>会将所有对象分为三种颜色，白灰黑，分别代表三种不同状态。白色：未扫描，灰色：已扫描，黑色：已标记。</p><ol><li>GC启动时，所有对象初始状态都是白色，GC会对根对象集合遍历，会将遍历到的对象置为灰色，并将其放到灰色队列中，直到遍历完所有根对象。</li><li>接下来会遍历灰色队列，会将灰色对象变为黑色，此时如果灰色对象有next节点，就将next节点变为灰色，写入灰色队列中, 重复这个步骤直到灰色队列为空。</li><li>最后剩余的白色对象就是垃圾对象，在sweep阶段stw被清除。</li></ol><p>tips: </p><ol><li>三色标记不是Go特有的，Java也有, 也算是一个主流的垃圾回收算法。</li><li>根对象集合: 全局变量、协程栈中变量、分配到堆空间的变量</li></ol><h2 id="为什么需要屏障？"><a href="#为什么需要屏障？" class="headerlink" title="为什么需要屏障？"></a>为什么需要屏障？</h2><p>在早期，GC会将所有用户态G停止运行(STW)，开始GC的扫描和清除工作，之后再唤醒用户态G,如果扫描对象或者清理对象过多, GC占用时间就过长，这对耗时敏感的服务来说是不可接受的， 因此Go团队着手优化GC，引入屏障机制，来最大化的让用户态goroutine和GCGoroutine并发执行。 为了能让mutator和collector并发执行(扫描阶段)，需要满足以下两个之一条件:</p><p>强三色不变式：</p><ul><li>黑色对象不能插入白色对象，只能将白色对象置灰</li></ul><p>弱三色不变式:</p><ul><li>黑色对象可以引用白色对象，但是白色对象必须被灰色对象引用(直接或者间接的，中间隔白色对象)</li></ul><p>为什么需要满足这俩条件? 如果不满足，GC可能会把正在引用的对象给误清理<br>举例:</p><ol><li>比如栈空间已经扫描完了，此时栈空间都是黑色对象，此时插入一个引用(白色对象)，GC会继续扫描进入sweep阶段，最后会直接把白色对象给清理。</li><li>如果白色对象被灰色对象引用，那就好办了，会在遍历灰色对象时一定能遍历到白色对象保证其不会被抛弃(即使白色被黑色引用)</li></ol><h3 id="删除屏障-了解即可-go未采用"><a href="#删除屏障-了解即可-go未采用" class="headerlink" title="删除屏障(了解即可,go未采用):"></a>删除屏障(了解即可,go未采用):</h3><ul><li>启动前，会做快照，被删对象如是白色会变灰色，灰色的话会变黑色</li><li>回收精度低，一个被删除对象就算没有被引用，本次GC不会被清理，下一轮GC才会被清理</li></ul><h3 id="插入屏障-go1-8之前"><a href="#插入屏障-go1-8之前" class="headerlink" title="插入屏障(go1.8之前)"></a>插入屏障(go1.8之前)</h3><ul><li>触发场景:  堆空间(栈空间不会触发) 。</li><li>满足强三色，如果黑色对象引用白色对象，会触发插入屏障<br>优点: 精度高<br>缺点: 需要对栈空间STW，栈空间重新扫描一遍，防止新插入的对象被清理。</li></ul><h3 id="混合写屏障-go1-8"><a href="#混合写屏障-go1-8" class="headerlink" title="混合写屏障(go1.8)"></a>混合写屏障(go1.8)</h3><ol><li>优点</li></ol><ul><li>GC启动时，会将栈空间的对象变为黑色，之后新增对象均为黑色</li><li>栈空间不触发屏障( 栈对象之间操作插入删除，不会有屏障效果,直接删除或插入)。</li><li>[堆空间] 中插入删除对象[堆空间]，被插入、删除对象都会变为灰色</li><li>交叉的这种，比如栈(黑对象)→堆(白)，无屏障效果直接插入白色；堆(灰对象)→栈(黑色)，无效果。</li><li>解决了栈重扫的问题</li></ul><ol start="2"><li>缺点: 还是存在精度问题，当删除对象引用时，被删除对象只能下一轮被清理</li></ol><p>tips: 堆空间对象→栈对象，插入或删除都无作用<br>Golang中的混合写屏障满足<code>弱三色不变式</code>，结合了删除写屏障和插入写屏障的优点，只需要在开始时并发扫描各个goroutine的栈，使其变黑并一直保持，这个过程不需要STW，而标记结束后，因为栈在扫描后始终是黑色的，也无需再进行re-scan操作了，减少了STW的时间。<br>插入屏障→混合写屏障</p><h1 id="GC调优"><a href="#GC调优" class="headerlink" title="GC调优"></a>GC调优</h1><p>Gc关注指标</p><ul><li>CPU使用率, GC的使用率不能过高，要提升mutator的使用率</li><li>GC频率, 如果频率过快，需要调整GCPercent</li><li>GC的STW时间, 需要关注mallocgc 查看分配对象的逻辑是否可以优化</li></ul><p>因此GC调优主要从两方面着手:</p><ul><li>GC频率控制</li><li>内存管理</li></ul><h2 id="GC频率控制"><a href="#GC频率控制" class="headerlink" title="GC频率控制:"></a>GC频率控制:</h2><ul><li>(不推荐)<a href="https://blog.twitch.tv/en/2019/04/10/go-memory-ballast-how-i-learnt-to-stop-worrying-and-love-the-heap/">ballast</a>: 压舱石技术，开辟一个大内存，可以一定程度避免频繁GC</li><li>(不推荐)<a href="https://github.com/cch123/gogctuner">GOGCTuner</a> 每次GC时动态调整GCPercent.</li><li>(推荐)GOGC或者<code>debug.SetGCPercent()</code> + <code>debug.SetMemoryLimit()</code></li></ul><p>如何选择合适的GCPercent值？</p><ol><li>先确定线上平均NextGC值</li><li>设置合理的<code>debug.SetMemoryLimit()</code>。（机器内存 &#x2F; 程序占用内存 * 2 )* 100%  一定不能超过这个值!</li><li>动态调整GCPercent、MemoryLimit，观察GC频次, 选最优的GCPercent值</li></ol><p>Next_GC(下次触发GC阈值) &#x3D; liveset(上次GC之后内存空间) + liveset * GCPercent<br>举例: 当前程序100M, <code>debug.SetGCPercent(100)</code>, NextGC &#x3D; 100 + 100 &#x3D; 200M</p><h3 id="！！注意别忘了设置-debug-SetMemoryLimit-or-GOMEMLIMIT-防止OOM"><a href="#！！注意别忘了设置-debug-SetMemoryLimit-or-GOMEMLIMIT-防止OOM" class="headerlink" title="！！注意别忘了设置 debug.SetMemoryLimit() or GOMEMLIMIT 防止OOM"></a>！！注意别忘了设置 <code>debug.SetMemoryLimit()</code> or <code>GOMEMLIMIT</code> 防止OOM</h3><h2 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h2><ol><li>sync.Pool 对象池复用对象</li><li>map&#x2F;slice 一次性申请提前分配好<br>ok:</li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs go">ret := <span class="hljs-built_in">make</span>([]<span class="hljs-type">int</span>, <span class="hljs-number">0</span> ,<span class="hljs-number">10</span>)<br><span class="hljs-keyword">for</span> i :=<span class="hljs-number">0</span>; i &lt; <span class="hljs-number">10</span>; i++ &#123;<br>ret[i] = i<br>&#125;<br></code></pre></td></tr></table></figure><p>Wrong:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">var</span> ret []<span class="hljs-type">int</span><br><span class="hljs-keyword">for</span> i :=<span class="hljs-number">0</span>; i &lt; <span class="hljs-number">10</span>; i++ &#123;<br>ret = <span class="hljs-built_in">append</span>(ret, i)<br>&#125;<br></code></pre></td></tr></table></figure><ol start="3"><li>字符串处理 string.Builder优先</li><li>控制Goroutine数量，Goroutine太多，会导致GC扫描的栈很多，也会影响mutator的CPU使用率</li></ol><h1 id="当前GC存在的问题："><a href="#当前GC存在的问题：" class="headerlink" title="当前GC存在的问题："></a>当前GC存在的问题：</h1><p>如果Goroutine很多，</p><ul><li>并且牵扯内存申请(mallocgc),MarkAssist 停顿时间长, 随着而来sweep内存清理也会长，</li><li>扫描的goroutine栈就多，cpu使用率也高</li></ul><h1 id="和其他语言GC对比"><a href="#和其他语言GC对比" class="headerlink" title="和其他语言GC对比"></a>和其他语言GC对比</h1><p>感兴趣可以看:<a href="https://www.topgoer.cn/docs/goquestions/goquestions-1cjh5nmtkbc4o">GC对比</a></p><h1 id="Resources"><a href="#Resources" class="headerlink" title="Resources:"></a>Resources:</h1><p><a href="https://github.com/aceld/golang/blob/main/5%E3%80%81Golang%E4%B8%89%E8%89%B2%E6%A0%87%E8%AE%B0+%E6%B7%B7%E5%90%88%E5%86%99%E5%B1%8F%E9%9A%9CGC%E6%A8%A1%E5%BC%8F%E5%85%A8%E5%88%86%E6%9E%90.md">刘丹冰GC文章,值得细读</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>GO</tag>
      
      <tag>GC</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
